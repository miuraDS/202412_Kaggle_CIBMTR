{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70942,"databundleVersionId":10381525,"sourceType":"competition"},{"sourceId":10575779,"sourceType":"datasetVersion","datasetId":6544534},{"sourceId":211253469,"sourceType":"kernelVersion"},{"sourceId":211322530,"sourceType":"kernelVersion"}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":10108.862432,"end_time":"2024-12-13T16:07:57.072385","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-12-13T13:19:28.209953","version":"2.6.0"},"colab":{"provenance":[],"machine_shape":"hm","include_colab_link":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/daiki-nakajima-createor/Kaggle_CIBMTR/blob/main/cibmtr-eda-ensemble-model-efs-xgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"このノートブックは、[Albanito](https://www.kaggle.com/albansteff)さんのノートブック[CIBMTR | EDA & Ensemble Model - Recalculate HLA](https://www.kaggle.com/code/albansteff/cibmtr-eda-ensemble-model-recalculate-hla)を元にしています。素晴らしい分析や洞察を共有していただきありがとうございます。","metadata":{"id":"L7RJK0B4ngBc"}},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Introduction</p>","metadata":{"id":"ae3ZHSpEngBd"}},{"cell_type":"markdown","source":"Addition in this notebook is the recalculation of HLA sums which are often missing. Since the sum is full of missing values, it was interesting to modify the values by recalculating them based on the data dictionary explanations and see the results.\n\nこのノートブックにおける追加事項は、しばしば欠けているHLA合計の再計算です。この合計は欠損値が多いため、データ辞書の説明に基づいて値を再計算し、その結果を確認することが興味深いものでした","metadata":{"id":"_Xur5jXkngBd"}},{"cell_type":"code","source":"# HLA : Human Leukocyte Antigen matching levels.\n# Homozygous chromosomes have the same allele at a given locus (fixed position on a chromosome where a particular gene is located).\n# Those that have different alleles at a given locus are called heterozygous.\n# Values Explanation\n# 0 - No Match: Neither of the donor's two HLA antigens/alleles matches the recipient's HLA.\n# This indicates a complete mismatch at the locus, which increases the risk of complications like graft rejection or graft-versus-host disease (GVHD).\n# 1 - Partial Match: One of the donor's HLA antigens/alleles matches one of the recipient's.\n# This represents a half-match (heterozygous compatibility) at the locus. It's better than a full mismatch but still carries a moderate risk of immune complications.\n# 2 - Full Match: Both of the donor's HLA match both of the recipient's HLA.\n# This is the optimal scenario, indicating full compatibility at the locus and minimizing the risk of immune complications.\n\n# High VS Low resolution\n\n# High-Resolution Typing: Identifies specific alleles (e.g., HLA-A*02:01).\n# Provides the most precise match and is essential for unrelated donor transplants.\n\n# Low-Resolution Typing: Identifies broader antigen groups (e.g., HLA-A2).\n# May suffice for related donor transplants where genetic similarity is inherently higher.\n\n# HLA: ヒト白血球抗原の一致レベルについて\n# ホモ接合染色体は、特定の遺伝子が位置する固定されたクロモソーム上の地点に同じ対立遺伝子を持っています。\n# 異なる対立遺伝子を持つものはヘテロ接合と呼ばれます。\n# 値の説明\n# 0 - 不一致: ドナーの2つのHLA抗原/対立遺伝子が受容者のHLAと一致しない。\n# これは、ラーカス（座位）での完全な不一致を示し、移植片拒絶や移植片対宿主病（GVHD）のような合併症のリスクを高めます。\n# 1 - 部分一致: ドナーのHLA抗原/対立遺伝子の1つが受容者のものと一致する。\n# これはラーカスでの半分の一致（ヘテロ接合の適合性）を表し、完全な不一致よりは良いですが、免疫の合併症のリスクは中程度あります。\n# 2 - 完全一致: ドナーの両方のHLAが受容者の両方のHLAと一致する。\n# これは最適なシナリオであり、ラーカスでの完全な適合性を示し、免疫合併症のリスクを最小限に抑えます。\n# 高解像度 VS 低解像度\n# 高解像度型: 特定の対立遺伝子を識別（例：HLA-A*02:01）。\n# 最も正確な一致を提供し、非関連ドナーの移植には不可欠です。\n# 低解像度型: より広い抗原グループを識別（例：HLA-A2）。\n# 遺伝的類似性が本質的に高い関連ドナーの移植には十分である場合があります。\n\nHLA_COLUMNS = [\n    # MHC class I molecules are one of two primary classes of major histocompatibility complex (MHC) molecules and are found on the cell surface of all nucleated cells.\n    # In humans, the HLAs corresponding to MHC class I are HLA-A, HLA-B, and HLA-C.\n\n#     MHCクラスI分子は、主要組織適合性複合体（MHC）分子の2つの主要なクラスのうちの1つで、すべての有核細胞の細胞表面に存在します。\n# ヒトでは、MHCクラスIに対応するHLAはHLA-A、HLA-B、HLA-Cです。\n    'hla_match_a_low', 'hla_match_a_high',\n    'hla_match_b_low', 'hla_match_b_high',\n    'hla_match_c_low', 'hla_match_c_high',\n\n    # MHC Class II molecules are a class of major histocompatibility complex (MHC) molecules normally found only on professional antigen-presenting cells\n    # such as dendritic cells, macrophages, some endothelial cells, thymic epithelial cells, and B cells.\n    # Antigens presented by MHC class II molecules are exogenous, originating from extracellular proteins rather than cytosolic and endogenous sources like\n    # those presented by MHC class I.\n    # HLAs corresponding to MHC class II are HLA-DP, HLA-DM, HLA-DOA, HLA-DOB, HLA-DQ, and HLA-DR.\n    # In this competition, we only have HLA-DR and HLA-DQ\n\n#     MHCクラスII分子は、通常、樹状細胞、マクロファージ、一部の内皮細胞、胸腺上皮細胞、B細胞などの専門の抗原提示細胞にのみ見られる主要組織適合性複合体（MHC）分子のクラスです。\n# MHCクラスII分子によって提示される抗原は外来由来であり、細胞質や内因性のソース（MHCクラスIによって提示されるもの）ではなく、細胞外タンパク質から由来しています。\n# MHCクラスIIに対応するHLAは、HLA-DP、HLA-DM、HLA-DOA、HLA-DOB、HLA-DQ、HLA-DRです。\n# この競技会では、HLA-DRとHLA-DQのみがあります。\n\n    # Visit https://en.wikipedia.org/wiki/HLA-DQB1\n\n    'hla_match_dqb1_low', 'hla_match_dqb1_high',\n    'hla_match_drb1_low', 'hla_match_drb1_high',\n\n    # Combination of matches : sum of matches between multiple categories\n\n    # Matching at HLA-A(low), -B(low), -DRB1(high)\n    'hla_nmdp_6',\n    # Matching at HLA-A,-B,-DRB1 (low or high)\n    'hla_low_res_6', 'hla_high_res_6',\n    # Matching at HLA-A, -B, -C, -DRB1 (low or high)\n    'hla_low_res_8', 'hla_high_res_8',\n    # Matching at HLA-A, -B, -C, -DRB1, -DQB1 (low or high)\n    'hla_low_res_10', 'hla_high_res_10'\n]","metadata":{"execution":{"iopub.status.busy":"2025-02-23T12:35:48.996387Z","iopub.execute_input":"2025-02-23T12:35:48.996892Z","iopub.status.idle":"2025-02-23T12:35:49.004791Z","shell.execute_reply.started":"2025-02-23T12:35:48.996861Z","shell.execute_reply":"2025-02-23T12:35:49.002895Z"},"trusted":true,"id":"h1IO3gLdngBd"},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"<div style=\"background-color: rgb(247, 230, 202); border: 4px solid rgb(162, 87, 79); border-radius: 40px; padding: 20px; font-family: 'Roboto'; color: rgb(162, 87, 79); text-align: left; font-size: 120%;\">\n    <ul style=\"list-style-type: square; padding-left: 20px;\">\n        <li>Missing values are replaced with:\n            <ul style=\"list-style-type: circle; margin-top: 10px; margin-bottom: 10px;\">\n                <li>-1 for numeric columns</li>\n                <li>Unknown for categorical columns</li>\n            </ul>\n        </li>\n        <li style=\"margin-top: 10px;\">\n            LightGBM and CatBoost are trained on 3 different targets, estimated from the survival models:\n            <ul style=\"list-style-type: circle; margin-top: 10px; margin-bottom: 10px;\">\n                <li>Cox</li>\n                <li>Kaplan-Meier</li>\n                <li>Nelson-Aalen</li>\n            </ul>\n        </li>\n        <li style=\"margin-top: 10px;\">Two additional CatBoost model are trained, with Cox loss function.</li>\n        <li style=\"margin-top: 10px;\">As per <a href=\"https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions/discussion/553061\" style=\"color: #A2574F; text-decoration: underline;\">this</a> discussion post, the target is consisted of the Out-of-Fold predictions of the survival models on the validation folds to prevent target leakage.</li>\n        <li style=\"margin-top: 10px;\">\n            The ensemble prediction for each sample is computed as:\n            <ul style=\"list-style-type: circle; margin-top: 10px; margin-bottom: 10px;\">\n                <p style=\"margin-top: 10px; font-size: 110%; color: #A2574F; font-family: 'Roboto'; text-align: left;\">\n                    $ \\text{preds}_{\\text{ensemble}} = \\sum_{i=1}^{n} w_i \\cdot \\text{rankdata}(\\text{preds}_i) $\n                </p>\n                where $n$ is the number of models, $w_i$ is the weight assigned to the $i$-th model, and $\\text{rankdata}(\\text{preds}_i)$ is the rank of predictions from the $i$-th model.\n            </ul>\n        </li>\n        <li style=\"margin-top: 10px;\">Last but not least, since the competition metric evaluates only the order of predictions and not their magnitude, the model weights are not required to sum to 1, nor should the predictions fall within a predefined range.</li>\n    </ul>\n</div>","metadata":{"id":"bTISvJXangBe"}},{"cell_type":"markdown","source":"<div style=\"background-color: rgb(247, 230, 202); border: 4px solid rgb(162, 87, 79); border-radius: 40px; padding: 20px; font-family: 'Roboto'; color: rgb(162, 87, 79); text-align: left; font-size: 120%;\">\n    <ul style=\"list-style-type: square; padding-left: 20px;\">\n        <li>欠損値は次の値で置換されます：\n            <ul style=\"list-style-type: circle; margin-top: 10px; margin-bottom: 10px;\">\n                <li>数値列には-1</li>\n                <li>カテゴリ列には\"Unknown\"</li>\n            </ul>\n        </li>\n        <li style=\"margin-top: 10px;\">\n            LightGBMおよびCatBoostは、生存モデルから推定された3つの異なるターゲットで訓練されます：\n            <ul style=\"list-style-type: circle; margin-top: 10px; margin-bottom: 10px;\">\n                <li>Cox</li>\n                <li>Kaplan-Meier</li>\n                <li>Nelson-Aalen</li>\n            </ul>\n        </li>\n        <li style=\"margin-top: 10px;\">さらに2つのCatBoostモデルがCox損失関数で訓練されます。</li>\n        <li style=\"margin-top: 10px;\"><a href=\"https://www.kaggle.com/competitions/equity-post-HCT-survival-predictions/discussion/553061\" style=\"color: #A2574F; text-decoration: underline;\">この</a>ディスカッション投稿に従い、ターゲットは、バリデーションフォールドにおける生存モデルのOut-of-Fold予測で構成され、ターゲットリーケージを防止します。</li>\n        <li style=\"margin-top: 10px;\">\n            各サンプルのアンサンブル予測は次のように計算されます：\n            <ul style=\"list-style-type: circle; margin-top: 10px; margin-bottom: 10px;\">\n                <p style=\"margin-top: 10px; font-size: 110%; color: #A2574F; font-family: 'Roboto'; text-align: left;\">\n                    $ \\text{preds}_{\\text{ensemble}} = \\sum_{i=1}^{n} w_i \\cdot \\text{rankdata}(\\text{preds}_i) $\n                </p>\n                ここで $n$ はモデルの数、 $w_i$ は$i$番目のモデルに割り当てられた重み、$\\text{rankdata}(\\text{preds}_i)$ は$i$番目のモデルからの予測のランクです。\n            </ul>\n        </li>\n        <li style=\"margin-top: 10px;\">最後に、コンペティションの評価指標は予測の大きさではなく順位のみを評価するため、モデルの重みが1に合計される必要はなく、予測が事前に定義された範囲に収まる必要もありません。</li>\n    </ul>\n</div>","metadata":{"id":"SrmsWVrEngBe"}},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Install Libraries</p>","metadata":{"papermill":{"duration":0.006361,"end_time":"2024-12-13T13:19:30.95227","exception":false,"start_time":"2024-12-13T13:19:30.945909","status":"completed"},"tags":[],"id":"FdtNDcgMngBe"}},{"cell_type":"code","source":"import os\nif \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n  !pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n  !pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n  !pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n  !pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n  !pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-02-23T12:35:49.006459Z","iopub.execute_input":"2025-02-23T12:35:49.006845Z","iopub.status.idle":"2025-02-23T12:36:16.025924Z","shell.execute_reply.started":"2025-02-23T12:35:49.006815Z","shell.execute_reply":"2025-02-23T12:36:16.024495Z"},"papermill":{"duration":215.181879,"end_time":"2024-12-13T13:23:06.140734","exception":false,"start_time":"2024-12-13T13:19:30.958855","status":"completed"},"tags":[],"trusted":true,"id":"yq5tETovngBf"},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd==1.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd==1.7.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->autograd==1.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->autograd==1.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->autograd==1.7.0) (2024.2.0)\nautograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\nBuilding wheels for collected packages: autograd-gamma\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=e8e7c3e4f2be0378f43dec285285bdf9de89838834972a2c33e83f3935cf2b61\n  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\nSuccessfully built autograd-gamma\nInstalling collected packages: autograd-gamma\nSuccessfully installed autograd-gamma-0.5.0\nProcessing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\nInstalling collected packages: interface-meta\nSuccessfully installed interface-meta-1.3.0\nProcessing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\nRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.3.0)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.26.4)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (2.2.2)\nRequirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.13.1)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (4.12.2)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->formulaic==1.0.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->formulaic==1.0.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\nInstalling collected packages: formulaic\nSuccessfully installed formulaic-1.0.2\nProcessing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\nRequirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.2.2)\nRequirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.5)\nRequirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\nRequirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\nRequirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.0.2)\nRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.17.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines==0.30.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->lifelines==0.30.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\nInstalling collected packages: lifelines\nSuccessfully installed lifelines-0.30.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Imports</p>","metadata":{"id":"mu0gmb4sngBf"}},{"cell_type":"code","source":"import warnings\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":0.017318,"end_time":"2024-12-13T13:23:06.166339","exception":false,"start_time":"2024-12-13T13:23:06.149021","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:16.028831Z","iopub.execute_input":"2025-02-23T12:36:16.029211Z","iopub.status.idle":"2025-02-23T12:36:16.034553Z","shell.execute_reply.started":"2025-02-23T12:36:16.029181Z","shell.execute_reply":"2025-02-23T12:36:16.033207Z"},"id":"JySzI_bzngBf"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport pandas as pd\nimport plotly.colors as pc\nimport plotly.express as px\nimport plotly.graph_objects as go","metadata":{"papermill":{"duration":1.790886,"end_time":"2024-12-13T13:23:07.965236","exception":false,"start_time":"2024-12-13T13:23:06.17435","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:16.036608Z","iopub.execute_input":"2025-02-23T12:36:16.036976Z","iopub.status.idle":"2025-02-23T12:36:18.107320Z","shell.execute_reply.started":"2025-02-23T12:36:16.036938Z","shell.execute_reply":"2025-02-23T12:36:18.106192Z"},"id":"bA9vqkAvngBf"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import plotly.io as pio\npio.renderers.default = 'iframe'","metadata":{"papermill":{"duration":0.172073,"end_time":"2024-12-13T13:23:08.145731","exception":false,"start_time":"2024-12-13T13:23:07.973658","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:18.108425Z","iopub.execute_input":"2025-02-23T12:36:18.109026Z","iopub.status.idle":"2025-02-23T12:36:18.335486Z","shell.execute_reply.started":"2025-02-23T12:36:18.108993Z","shell.execute_reply":"2025-02-23T12:36:18.334352Z"},"id":"Ird5E2FxngBf"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"if \"COLAB_GPU\" in os.environ:\n  !pip install lifelines\n  !pip install catboost\n  !pip install lightgbm","metadata":{"id":"KjUCdeq5o2LG","outputId":"0a75026c-23ac-41ad-b13c-bde703c4e2d7","trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:18.336600Z","iopub.execute_input":"2025-02-23T12:36:18.336979Z","iopub.status.idle":"2025-02-23T12:36:18.343010Z","shell.execute_reply.started":"2025-02-23T12:36:18.336942Z","shell.execute_reply":"2025-02-23T12:36:18.341735Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import lightgbm as lgb\n\nfrom scipy.stats import rankdata\nfrom catboost import CatBoostRegressor\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import KFold\nimport joblib\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom datetime import datetime\nfrom scipy.stats import yeojohnson\nimport xgboost as xgb\n\n# 全てのカラムを表示するオプションを設定\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","metadata":{"papermill":{"duration":3.110445,"end_time":"2024-12-13T13:23:11.289976","exception":false,"start_time":"2024-12-13T13:23:08.179531","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:18.344431Z","iopub.execute_input":"2025-02-23T12:36:18.344855Z","iopub.status.idle":"2025-02-23T12:36:23.121527Z","shell.execute_reply.started":"2025-02-23T12:36:18.344803Z","shell.execute_reply":"2025-02-23T12:36:23.120189Z"},"id":"0kVhfJo8ngBf"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"if \"COLAB_GPU\" in os.environ:\n  import sys\n  sys.path.append('/content/drive/MyDrive/Kaggle/20250215_CIBMTR')\n\n\n  print(\"Google Colab で実行中\")\n  from google.colab import drive\n  drive.mount('/content/drive')\n  # CSVファイルのパスを指定\n  csv_file_path = \"/content/drive/MyDrive/Kaggle/20250215_CIBMTR/death_rate.csv\"\n  # 現在の日時を取得してフォーマット\n  current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n  # ディレクトリ名を作成\n  directory_name = f\"/content/drive/MyDrive/Kaggle/20250215_CIBMTR/model_{current_datetime}\"\n\n  # ディレクトリのパスを指定\n  directory_path = Path(directory_name)\n\n  # ディレクトリを作成\n  directory_path.mkdir(parents=True, exist_ok=True)\n\n  train_path = Path('/content/drive/MyDrive/Kaggle/20250215_CIBMTR/data/train.csv')\n  test_path = Path('/content/drive/MyDrive/Kaggle/20250215_CIBMTR/data/test.csv')\n  subm_path = Path('/content/drive/MyDrive/Kaggle/20250215_CIBMTR/data/sample_submission.csv')\n\n\nelif \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n  !pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n  !pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n  !pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n  !pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n  !pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\n\n\n\n\n  # CSVファイルのパスを指定\n  csv_file_path = \"/kaggle/input/world-age-death-rate/death_rate.csv\"\n  # 現在の日時を取得してフォーマット\n  current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n  # ディレクトリ名を作成\n  directory_name = f\"model_{current_datetime}\"\n\n  # ディレクトリのパスを指定\n  directory_path = Path(directory_name)\n\n  # ディレクトリを作成\n  directory_path.mkdir(parents=True, exist_ok=True)\n  print(\"Kaggle Notebooks で実行中\")\n\n  train_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n  test_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n  subm_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv')\nelse:\n  print(\"ローカル環境または他の環境で実行中\")","metadata":{"id":"RGqzT0ENpBtM","outputId":"dfb02502-cf31-4dda-c902-37caac7aa24f","trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:23.125801Z","iopub.execute_input":"2025-02-23T12:36:23.126916Z","iopub.status.idle":"2025-02-23T12:36:48.525381Z","shell.execute_reply.started":"2025-02-23T12:36:23.126866Z","shell.execute_reply":"2025-02-23T12:36:48.523720Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd==1.7.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd==1.7.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->autograd==1.7.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->autograd==1.7.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->autograd==1.7.0) (2024.2.0)\nautograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\nBuilding wheels for collected packages: autograd-gamma\n  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=6be901482ea3c5920025a2ef294283321df4c0492380decaec37e300a5c71de4\n  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\nSuccessfully built autograd-gamma\nInstalling collected packages: autograd-gamma\n  Attempting uninstall: autograd-gamma\n    Found existing installation: autograd-gamma 0.5.0\n    Uninstalling autograd-gamma-0.5.0:\n      Successfully uninstalled autograd-gamma-0.5.0\nSuccessfully installed autograd-gamma-0.5.0\nProcessing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\ninterface-meta is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\nRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.3.0)\nRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.26.4)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (2.2.2)\nRequirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.13.1)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (4.12.2)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->formulaic==1.0.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->formulaic==1.0.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\nformulaic is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\nRequirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.2.2)\nRequirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.5)\nRequirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\nRequirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\nRequirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.0.2)\nRequirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\nRequirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.17.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines==0.30.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->lifelines==0.30.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\nlifelines is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nKaggle Notebooks で実行中\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from metric import score\nfrom lifelines import CoxPHFitter\nfrom lifelines import KaplanMeierFitter\nfrom lifelines import NelsonAalenFitter","metadata":{"id":"tG2Xb9PTpp6i","trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:48.528259Z","iopub.execute_input":"2025-02-23T12:36:48.528620Z","iopub.status.idle":"2025-02-23T12:36:48.738349Z","shell.execute_reply.started":"2025-02-23T12:36:48.528587Z","shell.execute_reply":"2025-02-23T12:36:48.737231Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Configuration</p>","metadata":{"papermill":{"duration":0.00881,"end_time":"2024-12-13T13:23:11.307141","exception":false,"start_time":"2024-12-13T13:23:11.298331","status":"completed"},"tags":[],"id":"H-oZt4-JngBg"}},{"cell_type":"code","source":"class CFG:\n\n    train_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n    test_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')\n    subm_path = Path('/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv')\n\n    color = '#A2574F'\n\n    batch_size = 32768\n    early_stop = 300\n    penalizer = 0.01\n    n_splits = 5\n\n    weights = [1.0, 1.0, 8.0, 4.0, 8.0, 4.0, 6.0, 6.0]\n\n# loss_function :\n# モデルの損失関数を指定します。この例ではRMSE（Root Mean Squared Error）を使っており、回帰問題において予測値の誤差を評価するために用いられます。\n# learning_rate :\n# 学習率は、モデルが訓練データから学び取る際のステップサイズを決定します。この値が小さければ小さいほど、学習がより慎重に行われるため、収束が遅くなる可能性がありますが、過学習を抑えることができる場合があります。この例では0.03に設定されています。\n# random_state :\n# ランダムシードの値を設定し、再現性を確保します。この値を固定することで、毎回同じデータ分割や初期状態で実験を行うことができます。この値が42に設定されています。\n# task_type :\n# モデルの実行に使用する計算リソースのタイプを指定します。この例ではGPUが設定されているため、GPUを使用して計算が行われます。コメントアウトされたCPUは、CPUを使用するオプションです。\n# num_trees :\n# 学習に使用するツリーの数を指定します。この例では6000に設定されており、多くのツリーを用いることでモデルの表現力を高めることができますが、過学習のリスクも増えるため、適切な早期停止の設定が重要です。\n# subsample :\n# サンプリング比率を指定します。この値は、各ツリーを訓練する際に使用されるデータの割合を示します。この例では0.85となっており、85%のデータを使って各ツリーを学習することを示します。これにより過学習を抑える効果があります。\n# reg_lambda :\n# L2正則化項の係数を指定します。正則化は過学習を防ぐための手法の一つで、モデルの重みが過度に大きくならないように制約を与えます。この値が大きいほど、モデルの複雑さが制約されます。この例では8.0に設定されています。\n# depth :\n# 各決定木の深さを指定します。この値が大きいほど、モデルはより複雑なパターンを学習できますが、過学習のリスクも高まります。この例では8に設定されています。\n# bootstrap_type :\n# ブートストラップサンプリングの手法を指定します。この例ではBernoulliが選択されています。Bernoulliブートストラップは、各サンプリングごとにデータポイントを独立に選ぶ方法です。他のオプションとしては、No（ブートストラップを使用しない）やMVS（モンテカルロボンディング）などがあります。\n\n    ctb_params_1 = {\n        'loss_function': 'RMSE',\n        'learning_rate': 0.02,\n        'random_state': 42,\n        'task_type': 'CPU',\n        # 'task_type': 'GPU',\n        'num_trees': 10000,\n        'subsample': 0.8,\n        'reg_lambda': 7.0,\n        'depth': 7,\n        'max_bin': 255\n        # 'bootstrap_type': 'Bernoulli'\n    }\n    ctb_params_23 = {\n        'loss_function': 'RMSE',\n        'learning_rate': 0.02,\n        'random_state': 42,\n        'task_type': 'CPU',\n        # 'task_type': 'GPU',\n        'num_trees': 10000,\n        'subsample': 0.8,\n        'reg_lambda': 7.0,\n        'depth': 7,\n        'max_bin': 255\n        # 'bootstrap_type': 'Bernoulli'\n    }\n\n    ctb_params_efs = {\n        \"loss_function\": \"Logloss\",\n        'learning_rate': 0.02,\n        'random_state': 42,\n        'task_type': 'CPU',\n        # 'task_type': 'GPU',\n        'num_trees': 10000,\n        'subsample': 0.8,\n        'reg_lambda': 7.0,\n        'depth': 7,\n        'max_bin': 255,\n        \"eval_metric\":\"Logloss\",\n        # 'bootstrap_type': 'Bernoulli'\n    }\n#     LightGBMパラメータの説明\n# objective :\n# モデルの目的を定義します。この例ではregressionと指定されており、回帰問題において連続値の予測を行うことを示しています。用途によってbinary（二値分類）やmulticlass（多クラス分類）なども指定できます。\n# min_child_samples :\n# 子ノードに必要な最小のデータサンプル数を指定します。この値が大きいほど、ノードが分割されるために必要なサンプル数も増え、過学習を抑制する働きがあります。この例では32に設定されています。\n# num_iterations :\n# 学習に使用するブースティングのイテレーション回数（決定木の数）を指定します。この例では6000に設定されており、モデルの収束を図るために多くの木を使用しますが、過学習のリスクも考慮する必要があります。\n# learning_rate :\n# 学習率を指定し、学習の速度を調整します。この値が小さいほど、モデルはより慎重に学習を進めることができ、安定性が増しますが、収束が遅くなる可能性があります。この例では0.03に設定されています。\n# extra_trees :\n# Trueに設定すると、より多様な木を構築するために、ノードの分割をランダムに行うことができます。これにより、モデルのバリエーションが増え、過学習を抑制する効果があります。\n# reg_lambda :\n# L2正則化項の係数を指定します。大きい値を設定することで、モデルの複雑度を制限し、過学習を防ぐ助けになります。この例では8.0に設定されています。\n# reg_alpha :\n# L1正則化項の係数を指定します。L1正則化はモデルの重みをゼロにすることがあり、特徴選択の効果を持つことがあります。この例では0.1に設定されています。\n# num_leaves :\n# 決定木の最大葉ノード数を指定します。この値が大きいほど、モデルの表現力が増しますが、過学習のリスクも高まります。この例では64に設定されています。\n# metric :\n# モデルの評価指標を指定します。この例ではrmseが設定されており、モデルの性能を根平均二乗誤差で評価します。\n# max_depth :\n# 決定木の最大深さを指定します。この値を設定することで、過学習を防ぎ、モデルの構造を制約することができます。この例では8に設定されています。\n# device :\n# モデルの実行に使用するデバイスを指定します。この例ではgpuが設定されており、GPUを使用して計算を行うことを示しています。コメントアウトされているcpuはCPUを使用するオプションです。\n# max_bin :\n# 特徴量のビンの最大数を指定します。この値を設定することで、カテゴリカルデータや連続値をどれだけ細かく分割するかを決定します。この例では128に設定されています。\n# verbose :\n# ログの出力レベルを指定します。-1に設定すると、情報メッセージを出力しないことを示しています。\n# seed :\n# ランダムシードの値を指定します。この値を固定しておくことで、再現性を確保することができます。この例では42に設定されています。\n\n    lgb_params_efs = {\n        'objective': 'binary',\n        'min_child_samples': 80,\n        'num_iterations': 6000,\n        'learning_rate': 0.02,\n        'extra_trees': False,\n        'reg_lambda': 7.0,\n        'reg_alpha': 1.0,\n        'num_leaves': 50,\n        'metric': 'logloss',\n        'max_depth': -1,\n        # 'device': 'gpu',\n        'device': 'cpu',\n        'max_bin': 255,\n        'subsample': 0.8,            # データのサンプリング率\n        'verbose': -1,\n        'seed': 42\n    }\n\n    lgb_params_1 = {\n        'objective': 'regression',\n        'min_child_samples': 80,\n        'num_iterations': 6000,\n        'learning_rate': 0.02,\n        'extra_trees': False,\n        'reg_lambda': 7.0,\n        'reg_alpha': 1.0,\n        'num_leaves': 50,\n        'metric': 'rmse',\n        'max_depth': -1,\n        # 'device': 'gpu',\n        'device': 'cpu',\n        'max_bin': 255,\n        'subsample': 0.8,            # データのサンプリング率\n        'verbose': -1,\n        'seed': 42\n    }\n\n    xgb_params = {\n    'objective': 'reg:squarederror',  # 回帰タスク用の損失関数\n    'eval_metric': 'rmse',           # 評価指標\n    'learning_rate': 0.02,           # 学習率（低めに設定）\n    'max_depth': 7,                  # ツリーの深さ\n    'subsample': 0.8,                # サンプリング率\n    'colsample_bytree': 0.8,         # 特徴量のサンプリング率\n    'lambda': 7.0,                   # L2正則化\n    'alpha': 0.0,                    # L1正則化（必要に応じて調整）\n    'n_estimators': 10000,           # ツリーの本数（早期停止で自動制御）\n    'tree_method': 'hist',           # ツリー構築アルゴリズム（CPU用）\n    'random_state': 42,              # 再現性のための乱数シード\n    # 'early_stopping_rounds': 300     # 早期停止\n}\n\n    xgb_params_efs = {\n    'objective': \"binary:logistic\",  # 二値分類\n    'eval_metric': 'logloss',        # 評価指標\n    'learning_rate': 0.02,           # 学習率（低めに設定）\n    'max_depth': 7,                  # ツリーの深さ\n    'subsample': 0.8,                # サンプリング率\n    'colsample_bytree': 0.8,         # 特徴量のサンプリング率\n    'lambda': 7.0,                   # L2正則化\n    'alpha': 0.0,                    # L1正則化（必要に応じて調整）\n    'n_estimators': 10000,           # ツリーの本数（早期停止で自動制御）\n    'tree_method': 'hist',           # ツリー構築アルゴリズム（CPU用）\n    'random_state': 42,              # 再現性のための乱数シード\n    # 'early_stopping_rounds': 300     # 早期停止\n}\n\n    lgb_params_23 = {\n        'objective': 'regression',\n        'min_child_samples': 32,\n        'num_iterations': 12000,\n        'learning_rate': 0.03,\n        'extra_trees': True,\n        'reg_lambda': 6.0,\n        'reg_alpha': 0.1,\n        'num_leaves': 64,\n        'metric': 'rmse',\n        'max_depth': 8,\n        # 'device': 'gpu',\n        'device': 'cpu',\n        'max_bin': 128,\n        'verbose': -1,\n        'seed': 42\n    }\n\n    # Parameters for the first CatBoost model with Cox loss function\n    cox1_params = {\n        'grow_policy': 'Depthwise',\n        'min_child_samples': 8,\n        'loss_function': 'Cox',\n        'learning_rate': 0.02,\n        'random_state': 42,\n        # 'task_type': 'GPU',\n        'task_type': 'CPU',\n        'num_trees': 10000,\n        'subsample': 0.8,\n        'reg_lambda': 7.0,\n        'depth': 7,\n        'max_bin': 255\n        # 'bootstrap_type': 'Bernoulli'\n    }\n\n    # Parameters for the second CatBoost model with Cox loss function\n    cox2_params = {\n        'grow_policy': 'Lossguide',\n        'loss_function': 'Cox',\n        'learning_rate': 0.02,\n        'random_state': 42,\n        'task_type': 'CPU',\n        # 'task_type': 'GPU',\n        'num_trees': 10000,\n        'subsample': 0.8,\n        'reg_lambda': 7.0,\n        'num_leaves': 32,\n        'depth': 7,\n        'max_bin': 255\n        # 'bootstrap_type': 'Bernoulli'\n    }","metadata":{"papermill":{"duration":0.019849,"end_time":"2024-12-13T13:23:11.335144","exception":false,"start_time":"2024-12-13T13:23:11.315295","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:48.739589Z","iopub.execute_input":"2025-02-23T12:36:48.740013Z","iopub.status.idle":"2025-02-23T12:36:48.755681Z","shell.execute_reply.started":"2025-02-23T12:36:48.739980Z","shell.execute_reply":"2025-02-23T12:36:48.754386Z"},"id":"4lnqS2hBngBg"},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Feature Engineering</p>","metadata":{"papermill":{"duration":0.007982,"end_time":"2024-12-13T13:23:11.351542","exception":false,"start_time":"2024-12-13T13:23:11.34356","status":"completed"},"tags":[],"id":"EnVdPQujngBg"}},{"cell_type":"code","source":"class FE:\n\n    def __init__(self, batch_size):\n        self._batch_size = batch_size\n\n    def load_data(self, path):\n#  batch_size\n# データをどの程度の大きさで分割して読み込むかを指定。\n# 大規模データを扱う際に、メモリ消費量を制御するために使用\n        return pl.read_csv(path, batch_size=self._batch_size)\n\n    def recalculate_hla_sums(self, df):\n        # Polarsライブラリを使用してデータフレーム（df）に新しい列を追加します。各新しい列は、特定のHLAマッチング列の合計値を計算し、それらの欠損値（Null）はゼロで補完\n\n        df = df.with_columns(\n            # hla_match_a_low, hla_match_b_low, hla_match_drb1_highの各列の値（欠損値を0で補完）を合計。\n            (pl.col(\"hla_match_a_low\").fill_null(0) + pl.col(\"hla_match_b_low\").fill_null(0) +\n             pl.col(\"hla_match_drb1_high\").fill_null(0)).alias(\"hla_nmdp_6\"),\n\n            (pl.col(\"hla_match_a_low\").fill_null(0) + pl.col(\"hla_match_b_low\").fill_null(0) +\n             pl.col(\"hla_match_drb1_low\").fill_null(0)).alias(\"hla_low_res_6\"),\n\n            (pl.col(\"hla_match_a_high\").fill_null(0) + pl.col(\"hla_match_b_high\").fill_null(0) +\n             pl.col(\"hla_match_drb1_high\").fill_null(0)).alias(\"hla_high_res_6\"),\n\n            (pl.col(\"hla_match_a_low\").fill_null(0) + pl.col(\"hla_match_b_low\").fill_null(0) +\n             pl.col(\"hla_match_c_low\").fill_null(0) + pl.col(\"hla_match_drb1_low\").fill_null(0)\n            ).alias(\"hla_low_res_8\"),\n\n            (pl.col(\"hla_match_a_high\").fill_null(0) + pl.col(\"hla_match_b_high\").fill_null(0) +\n             pl.col(\"hla_match_c_high\").fill_null(0) + pl.col(\"hla_match_drb1_high\").fill_null(0)\n            ).alias(\"hla_high_res_8\"),\n\n            (pl.col(\"hla_match_a_low\").fill_null(0) + pl.col(\"hla_match_b_low\").fill_null(0) +\n             pl.col(\"hla_match_c_low\").fill_null(0) + pl.col(\"hla_match_drb1_low\").fill_null(0) +\n             pl.col(\"hla_match_dqb1_low\").fill_null(0)).alias(\"hla_low_res_10\"),\n\n            (pl.col(\"hla_match_a_high\").fill_null(0) + pl.col(\"hla_match_b_high\").fill_null(0) +\n             pl.col(\"hla_match_c_high\").fill_null(0) + pl.col(\"hla_match_drb1_high\").fill_null(0) +\n             pl.col(\"hla_match_dqb1_high\").fill_null(0)).alias(\"hla_high_res_10\"),\n\n             (pl.col(\"diabetes\").cast(pl.Utf8) + \"_\" + pl.col(\"obesity\").cast(pl.Utf8)).alias(\"diabetes_obesity\").cast(pl.Utf8),\n            (pl.col(\"donor_age\") - pl.col(\"age_at_hct\")).alias(\"age_diff_donor-reci\"),\n            (pl.col(\"donor_age\") - pl.col(\"age_at_hct\")).alias(\"age_rate_donor-reci\"),\n            (pl.col(\"year_hct\") - 2000).alias(\"year_hct\")\n        )\n\n        return df\n\n    def cast_datatypes(self, df):\n\n        num_cols = [\n            'hla_high_res_8',\n            'hla_low_res_8',\n            'hla_high_res_6',\n            'hla_low_res_6',\n            'hla_high_res_10',\n            'hla_low_res_10',\n            'hla_match_dqb1_high',\n            'hla_match_dqb1_low',\n            'hla_match_drb1_high',\n            'hla_match_drb1_low',\n            'hla_nmdp_6',\n            'year_hct',\n            'hla_match_a_high',\n            'hla_match_a_low',\n            'hla_match_b_high',\n            'hla_match_b_low',\n            'hla_match_c_high',\n            'hla_match_c_low',\n            'donor_age',\n            'age_at_hct',\n            'comorbidity_score',\n            'karnofsky_score',\n            'efs',\n            'efs_time',\n            \"age_rate_donor-reci\",\n            \"year_hct\",\n            \"age_diff_donor-reci\",   \n        ]\n\n        for col in df.columns:\n\n            if col in num_cols:\n                df = df.with_columns(pl.col(col).fill_null(-1).cast(pl.Float32))\n\n            else:\n                df = df.with_columns(pl.col(col).fill_null('Unknown').cast(pl.String))\n\n        return df.with_columns(pl.col('ID').cast(pl.Int32))\n\n    def info(self, df):\n\n        print(f'\\nShape of dataframe: {df.shape}')\n\n        mem = df.memory_usage().sum() / 1024**2\n        print('Memory usage: {:.2f} MB\\n'.format(mem))\n\n        display(df.head())\n\n    def apply_fe(self, path):\n\n        df = self.load_data(path)\n        df = self.recalculate_hla_sums(df)\n        df = self.cast_datatypes(df)\n        df = df.to_pandas()\n\n        self.info(df)\n\n        cat_cols = [col for col in df.columns if df[col].dtype == pl.String]\n\n        return df, cat_cols","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.022682,"end_time":"2024-12-13T13:23:11.382481","exception":false,"start_time":"2024-12-13T13:23:11.359799","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:48.756996Z","iopub.execute_input":"2025-02-23T12:36:48.757332Z","iopub.status.idle":"2025-02-23T12:36:48.781391Z","shell.execute_reply.started":"2025-02-23T12:36:48.757305Z","shell.execute_reply":"2025-02-23T12:36:48.780209Z"},"id":"BfeMd_dCngBg"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"fe = FE(CFG.batch_size)","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.016709,"end_time":"2024-12-13T13:23:11.407504","exception":false,"start_time":"2024-12-13T13:23:11.390795","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:48.782674Z","iopub.execute_input":"2025-02-23T12:36:48.783107Z","iopub.status.idle":"2025-02-23T12:36:48.801566Z","shell.execute_reply.started":"2025-02-23T12:36:48.783045Z","shell.execute_reply":"2025-02-23T12:36:48.800356Z"},"id":"0drIKEjengBg"},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_data, cat_cols = fe.apply_fe(train_path)","metadata":{"papermill":{"duration":0.726911,"end_time":"2024-12-13T13:23:12.142797","exception":false,"start_time":"2024-12-13T13:23:11.415886","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:48.802638Z","iopub.execute_input":"2025-02-23T12:36:48.802910Z","iopub.status.idle":"2025-02-23T12:36:49.280098Z","shell.execute_reply.started":"2025-02-23T12:36:48.802887Z","shell.execute_reply":"2025-02-23T12:36:49.279017Z"},"id":"4z12A8j-ngBg","outputId":"b73286cc-9cb7-49ba-8da4-74834f5abb23"},"outputs":[{"name":"stdout","text":"\nShape of dataframe: (28800, 63)\nMemory usage: 10.88 MB\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   ID                       dri_score psych_disturb    cyto_score diabetes  \\\n0   0  N/A - non-malignant indication            No       Unknown       No   \n1   1                    Intermediate            No  Intermediate       No   \n2   2  N/A - non-malignant indication            No       Unknown       No   \n3   3                            High            No  Intermediate       No   \n4   4                            High            No       Unknown       No   \n\n   hla_match_c_high  hla_high_res_8          tbi_status arrhythmia  \\\n0              -1.0             6.0              No TBI         No   \n1               2.0             8.0  TBI +- Other, >cGy         No   \n2               2.0             8.0              No TBI         No   \n3               2.0             8.0              No TBI         No   \n4               2.0             8.0              No TBI         No   \n\n   hla_low_res_6        graft_type vent_hist renal_issue pulm_severe  \\\n0            6.0       Bone marrow        No          No          No   \n1            6.0  Peripheral blood        No          No          No   \n2            6.0       Bone marrow        No          No          No   \n3            6.0       Bone marrow        No          No          No   \n4            6.0  Peripheral blood        No          No          No   \n\n  prim_disease_hct  hla_high_res_6 cmv_status  hla_high_res_10  \\\n0              IEA             6.0        +/+              8.0   \n1              AML             6.0        +/+             10.0   \n2              HIS             6.0        +/+             10.0   \n3              ALL             6.0        +/+             10.0   \n4              MPN             6.0        +/+             10.0   \n\n   hla_match_dqb1_high tce_imm_match  hla_nmdp_6  hla_match_c_low rituximab  \\\n0                  2.0       Unknown         6.0              2.0        No   \n1                  2.0           P/P         6.0              2.0        No   \n2                  2.0           P/P         6.0              2.0        No   \n3                  2.0           P/P         6.0              2.0        No   \n4                  2.0       Unknown         6.0              2.0        No   \n\n   hla_match_drb1_low  hla_match_dqb1_low prod_type cyto_score_detail  \\\n0                 2.0                 2.0        BM           Unknown   \n1                 2.0                 2.0        PB      Intermediate   \n2                 2.0                 2.0        BM           Unknown   \n3                 2.0                 2.0        BM      Intermediate   \n4                 2.0                 2.0        PB           Unknown   \n\n  conditioning_intensity               ethnicity  year_hct obesity   mrd_hct  \\\n0                Unknown  Not Hispanic or Latino      16.0      No   Unknown   \n1                    MAC  Not Hispanic or Latino       8.0      No  Positive   \n2                Unknown  Not Hispanic or Latino      19.0      No   Unknown   \n3                    MAC  Not Hispanic or Latino       9.0      No  Positive   \n4                    MAC      Hispanic or Latino      18.0      No   Unknown   \n\n  in_vivo_tcd   tce_match  hla_match_a_high hepatic_severe  donor_age  \\\n0         Yes     Unknown               2.0             No  -1.000000   \n1          No  Permissive               2.0             No  72.290001   \n2         Yes     Unknown               2.0             No  -1.000000   \n3          No  Permissive               2.0             No  29.230000   \n4         Yes     Unknown               2.0             No  56.810001   \n\n  prior_tumor  hla_match_b_low peptic_ulcer  age_at_hct  hla_match_a_low  \\\n0          No              2.0           No    9.942000              2.0   \n1          No              2.0           No   43.705002              2.0   \n2          No              2.0           No   33.997002              2.0   \n3          No              2.0           No   43.244999              2.0   \n4          No              2.0           No   29.740000              2.0   \n\n               gvhd_proph rheum_issue sex_match  hla_match_b_high  \\\n0                 FKalone          No       M-F               2.0   \n1  Other GVHD Prophylaxis          No       F-F               2.0   \n2  Cyclophosphamide alone          No       F-M               2.0   \n3       FK+ MMF +- others          No       M-M               2.0   \n4     TDEPLETION +- other          No       M-F               2.0   \n\n                         race_group  comorbidity_score  karnofsky_score  \\\n0                More than one race                0.0             90.0   \n1                             Asian                3.0             90.0   \n2                More than one race                0.0             90.0   \n3                             White                0.0             90.0   \n4  American Indian or Alaska Native                1.0             90.0   \n\n  hepatic_mild          tce_div_match donor_related      melphalan_dose  \\\n0           No                Unknown     Unrelated  N/A, Mel not given   \n1           No  Permissive mismatched       Related  N/A, Mel not given   \n2           No  Permissive mismatched       Related  N/A, Mel not given   \n3          Yes  Permissive mismatched     Unrelated  N/A, Mel not given   \n4           No  Permissive mismatched       Related                 MEL   \n\n   hla_low_res_8 cardiac  hla_match_drb1_high pulm_moderate  hla_low_res_10  \\\n0            8.0      No                  2.0            No            10.0   \n1            8.0      No                  2.0           Yes            10.0   \n2            8.0      No                  2.0            No            10.0   \n3            8.0      No                  2.0            No            10.0   \n4            8.0      No                  2.0            No            10.0   \n\n   efs    efs_time diabetes_obesity  age_diff_donor-reci  age_rate_donor-reci  \n0  0.0   42.355999            No_No            -1.000000            -1.000000  \n1  1.0    4.672000            No_No            28.584999            28.584999  \n2  0.0   19.792999            No_No            -1.000000            -1.000000  \n3  0.0  102.348999            No_No           -14.015000           -14.015000  \n4  0.0   16.223000            No_No            27.070000            27.070000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>dri_score</th>\n      <th>psych_disturb</th>\n      <th>cyto_score</th>\n      <th>diabetes</th>\n      <th>hla_match_c_high</th>\n      <th>hla_high_res_8</th>\n      <th>tbi_status</th>\n      <th>arrhythmia</th>\n      <th>hla_low_res_6</th>\n      <th>graft_type</th>\n      <th>vent_hist</th>\n      <th>renal_issue</th>\n      <th>pulm_severe</th>\n      <th>prim_disease_hct</th>\n      <th>hla_high_res_6</th>\n      <th>cmv_status</th>\n      <th>hla_high_res_10</th>\n      <th>hla_match_dqb1_high</th>\n      <th>tce_imm_match</th>\n      <th>hla_nmdp_6</th>\n      <th>hla_match_c_low</th>\n      <th>rituximab</th>\n      <th>hla_match_drb1_low</th>\n      <th>hla_match_dqb1_low</th>\n      <th>prod_type</th>\n      <th>cyto_score_detail</th>\n      <th>conditioning_intensity</th>\n      <th>ethnicity</th>\n      <th>year_hct</th>\n      <th>obesity</th>\n      <th>mrd_hct</th>\n      <th>in_vivo_tcd</th>\n      <th>tce_match</th>\n      <th>hla_match_a_high</th>\n      <th>hepatic_severe</th>\n      <th>donor_age</th>\n      <th>prior_tumor</th>\n      <th>hla_match_b_low</th>\n      <th>peptic_ulcer</th>\n      <th>age_at_hct</th>\n      <th>hla_match_a_low</th>\n      <th>gvhd_proph</th>\n      <th>rheum_issue</th>\n      <th>sex_match</th>\n      <th>hla_match_b_high</th>\n      <th>race_group</th>\n      <th>comorbidity_score</th>\n      <th>karnofsky_score</th>\n      <th>hepatic_mild</th>\n      <th>tce_div_match</th>\n      <th>donor_related</th>\n      <th>melphalan_dose</th>\n      <th>hla_low_res_8</th>\n      <th>cardiac</th>\n      <th>hla_match_drb1_high</th>\n      <th>pulm_moderate</th>\n      <th>hla_low_res_10</th>\n      <th>efs</th>\n      <th>efs_time</th>\n      <th>diabetes_obesity</th>\n      <th>age_diff_donor-reci</th>\n      <th>age_rate_donor-reci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>N/A - non-malignant indication</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>No</td>\n      <td>-1.0</td>\n      <td>6.0</td>\n      <td>No TBI</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Bone marrow</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>IEA</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>Unknown</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>BM</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Not Hispanic or Latino</td>\n      <td>16.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Yes</td>\n      <td>Unknown</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>-1.000000</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>9.942000</td>\n      <td>2.0</td>\n      <td>FKalone</td>\n      <td>No</td>\n      <td>M-F</td>\n      <td>2.0</td>\n      <td>More than one race</td>\n      <td>0.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Unrelated</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>42.355999</td>\n      <td>No_No</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Intermediate</td>\n      <td>No</td>\n      <td>Intermediate</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>TBI +- Other, &gt;cGy</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Peripheral blood</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>AML</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>P/P</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>PB</td>\n      <td>Intermediate</td>\n      <td>MAC</td>\n      <td>Not Hispanic or Latino</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>Positive</td>\n      <td>No</td>\n      <td>Permissive</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>72.290001</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>43.705002</td>\n      <td>2.0</td>\n      <td>Other GVHD Prophylaxis</td>\n      <td>No</td>\n      <td>F-F</td>\n      <td>2.0</td>\n      <td>Asian</td>\n      <td>3.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Permissive mismatched</td>\n      <td>Related</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>4.672000</td>\n      <td>No_No</td>\n      <td>28.584999</td>\n      <td>28.584999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>N/A - non-malignant indication</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>No TBI</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Bone marrow</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>HIS</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>P/P</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>BM</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Not Hispanic or Latino</td>\n      <td>19.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Yes</td>\n      <td>Unknown</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>-1.000000</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>33.997002</td>\n      <td>2.0</td>\n      <td>Cyclophosphamide alone</td>\n      <td>No</td>\n      <td>F-M</td>\n      <td>2.0</td>\n      <td>More than one race</td>\n      <td>0.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Permissive mismatched</td>\n      <td>Related</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>19.792999</td>\n      <td>No_No</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>High</td>\n      <td>No</td>\n      <td>Intermediate</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>No TBI</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Bone marrow</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>ALL</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>P/P</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>BM</td>\n      <td>Intermediate</td>\n      <td>MAC</td>\n      <td>Not Hispanic or Latino</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Positive</td>\n      <td>No</td>\n      <td>Permissive</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>29.230000</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>43.244999</td>\n      <td>2.0</td>\n      <td>FK+ MMF +- others</td>\n      <td>No</td>\n      <td>M-M</td>\n      <td>2.0</td>\n      <td>White</td>\n      <td>0.0</td>\n      <td>90.0</td>\n      <td>Yes</td>\n      <td>Permissive mismatched</td>\n      <td>Unrelated</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>102.348999</td>\n      <td>No_No</td>\n      <td>-14.015000</td>\n      <td>-14.015000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>High</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>No TBI</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Peripheral blood</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>MPN</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>Unknown</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>PB</td>\n      <td>Unknown</td>\n      <td>MAC</td>\n      <td>Hispanic or Latino</td>\n      <td>18.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Yes</td>\n      <td>Unknown</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>56.810001</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>29.740000</td>\n      <td>2.0</td>\n      <td>TDEPLETION +- other</td>\n      <td>No</td>\n      <td>M-F</td>\n      <td>2.0</td>\n      <td>American Indian or Alaska Native</td>\n      <td>1.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Permissive mismatched</td>\n      <td>Related</td>\n      <td>MEL</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>16.223000</td>\n      <td>No_No</td>\n      <td>27.070000</td>\n      <td>27.070000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"train_data[\"diabetes_obesity\"].fillna(\"NONE\").value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:49.281113Z","iopub.execute_input":"2025-02-23T12:36:49.281401Z","iopub.status.idle":"2025-02-23T12:36:49.299571Z","shell.execute_reply.started":"2025-02-23T12:36:49.281377Z","shell.execute_reply":"2025-02-23T12:36:49.298613Z"},"id":"N4AAdchVngBh","outputId":"8708732b-ef35-4ce7-82f1-cbb717f5cbb5"},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"diabetes_obesity\nNo_No                20490\nYes_No                3761\nUnknown               2621\nNo_Yes                1213\nYes_Yes                467\nNot done_No            122\nNo_Not done             84\nYes_Not done            27\nNot done_Yes            14\nNot done_Not done        1\nName: count, dtype: int64"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"test_data, _ = fe.apply_fe(test_path)","metadata":{"papermill":{"duration":0.075873,"end_time":"2024-12-13T13:23:12.227636","exception":false,"start_time":"2024-12-13T13:23:12.151763","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:49.300783Z","iopub.execute_input":"2025-02-23T12:36:49.301178Z","iopub.status.idle":"2025-02-23T12:36:49.378501Z","shell.execute_reply.started":"2025-02-23T12:36:49.301149Z","shell.execute_reply":"2025-02-23T12:36:49.377293Z"},"id":"nXwqc-AkngBh","outputId":"f18d31bc-2eea-4b88-afee-1ea33e005e5d"},"outputs":[{"name":"stdout","text":"\nShape of dataframe: (3, 61)\nMemory usage: 0.00 MB\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      ID                       dri_score psych_disturb    cyto_score diabetes  \\\n0  28800  N/A - non-malignant indication            No       Unknown       No   \n1  28801                    Intermediate            No  Intermediate       No   \n2  28802  N/A - non-malignant indication            No       Unknown       No   \n\n   hla_match_c_high  hla_high_res_8          tbi_status arrhythmia  \\\n0              -1.0             6.0              No TBI         No   \n1               2.0             8.0  TBI +- Other, >cGy         No   \n2               2.0             8.0              No TBI         No   \n\n   hla_low_res_6        graft_type vent_hist renal_issue pulm_severe  \\\n0            6.0       Bone marrow        No          No          No   \n1            6.0  Peripheral blood        No          No          No   \n2            6.0       Bone marrow        No          No          No   \n\n  prim_disease_hct  hla_high_res_6 cmv_status  hla_high_res_10  \\\n0              IEA             6.0        +/+              8.0   \n1              AML             6.0        +/+             10.0   \n2              HIS             6.0        +/+             10.0   \n\n   hla_match_dqb1_high tce_imm_match  hla_nmdp_6  hla_match_c_low rituximab  \\\n0                  2.0       Unknown         6.0              2.0        No   \n1                  2.0           P/P         6.0              2.0        No   \n2                  2.0           P/P         6.0              2.0        No   \n\n   hla_match_drb1_low  hla_match_dqb1_low prod_type cyto_score_detail  \\\n0                 2.0                 2.0        BM           Unknown   \n1                 2.0                 2.0        PB      Intermediate   \n2                 2.0                 2.0        BM           Unknown   \n\n  conditioning_intensity               ethnicity  year_hct obesity   mrd_hct  \\\n0                Unknown  Not Hispanic or Latino      16.0      No   Unknown   \n1                    MAC  Not Hispanic or Latino       8.0      No  Positive   \n2                Unknown  Not Hispanic or Latino      19.0      No   Unknown   \n\n  in_vivo_tcd   tce_match  hla_match_a_high hepatic_severe  donor_age  \\\n0         Yes     Unknown               2.0             No  -1.000000   \n1          No  Permissive               2.0             No  72.290001   \n2         Yes     Unknown               2.0             No  -1.000000   \n\n  prior_tumor  hla_match_b_low peptic_ulcer  age_at_hct  hla_match_a_low  \\\n0          No              2.0           No    9.942000              2.0   \n1          No              2.0           No   43.705002              2.0   \n2          No              2.0           No   33.997002              2.0   \n\n               gvhd_proph rheum_issue sex_match  hla_match_b_high  \\\n0                 FKalone          No       M-F               2.0   \n1  Other GVHD Prophylaxis          No       F-F               2.0   \n2  Cyclophosphamide alone          No       F-M               2.0   \n\n           race_group  comorbidity_score  karnofsky_score hepatic_mild  \\\n0  More than one race                0.0             90.0           No   \n1               Asian                3.0             90.0           No   \n2  More than one race                0.0             90.0           No   \n\n           tce_div_match donor_related      melphalan_dose  hla_low_res_8  \\\n0                Unknown     Unrelated  N/A, Mel not given            8.0   \n1  Permissive mismatched       Related  N/A, Mel not given            8.0   \n2  Permissive mismatched       Related  N/A, Mel not given            8.0   \n\n  cardiac  hla_match_drb1_high pulm_moderate  hla_low_res_10 diabetes_obesity  \\\n0      No                  2.0            No            10.0            No_No   \n1      No                  2.0           Yes            10.0            No_No   \n2      No                  2.0            No            10.0            No_No   \n\n   age_diff_donor-reci  age_rate_donor-reci  \n0            -1.000000            -1.000000  \n1            28.584999            28.584999  \n2            -1.000000            -1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>dri_score</th>\n      <th>psych_disturb</th>\n      <th>cyto_score</th>\n      <th>diabetes</th>\n      <th>hla_match_c_high</th>\n      <th>hla_high_res_8</th>\n      <th>tbi_status</th>\n      <th>arrhythmia</th>\n      <th>hla_low_res_6</th>\n      <th>graft_type</th>\n      <th>vent_hist</th>\n      <th>renal_issue</th>\n      <th>pulm_severe</th>\n      <th>prim_disease_hct</th>\n      <th>hla_high_res_6</th>\n      <th>cmv_status</th>\n      <th>hla_high_res_10</th>\n      <th>hla_match_dqb1_high</th>\n      <th>tce_imm_match</th>\n      <th>hla_nmdp_6</th>\n      <th>hla_match_c_low</th>\n      <th>rituximab</th>\n      <th>hla_match_drb1_low</th>\n      <th>hla_match_dqb1_low</th>\n      <th>prod_type</th>\n      <th>cyto_score_detail</th>\n      <th>conditioning_intensity</th>\n      <th>ethnicity</th>\n      <th>year_hct</th>\n      <th>obesity</th>\n      <th>mrd_hct</th>\n      <th>in_vivo_tcd</th>\n      <th>tce_match</th>\n      <th>hla_match_a_high</th>\n      <th>hepatic_severe</th>\n      <th>donor_age</th>\n      <th>prior_tumor</th>\n      <th>hla_match_b_low</th>\n      <th>peptic_ulcer</th>\n      <th>age_at_hct</th>\n      <th>hla_match_a_low</th>\n      <th>gvhd_proph</th>\n      <th>rheum_issue</th>\n      <th>sex_match</th>\n      <th>hla_match_b_high</th>\n      <th>race_group</th>\n      <th>comorbidity_score</th>\n      <th>karnofsky_score</th>\n      <th>hepatic_mild</th>\n      <th>tce_div_match</th>\n      <th>donor_related</th>\n      <th>melphalan_dose</th>\n      <th>hla_low_res_8</th>\n      <th>cardiac</th>\n      <th>hla_match_drb1_high</th>\n      <th>pulm_moderate</th>\n      <th>hla_low_res_10</th>\n      <th>diabetes_obesity</th>\n      <th>age_diff_donor-reci</th>\n      <th>age_rate_donor-reci</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28800</td>\n      <td>N/A - non-malignant indication</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>No</td>\n      <td>-1.0</td>\n      <td>6.0</td>\n      <td>No TBI</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Bone marrow</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>IEA</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>Unknown</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>BM</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Not Hispanic or Latino</td>\n      <td>16.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Yes</td>\n      <td>Unknown</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>-1.000000</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>9.942000</td>\n      <td>2.0</td>\n      <td>FKalone</td>\n      <td>No</td>\n      <td>M-F</td>\n      <td>2.0</td>\n      <td>More than one race</td>\n      <td>0.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Unrelated</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>10.0</td>\n      <td>No_No</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28801</td>\n      <td>Intermediate</td>\n      <td>No</td>\n      <td>Intermediate</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>TBI +- Other, &gt;cGy</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Peripheral blood</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>AML</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>P/P</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>PB</td>\n      <td>Intermediate</td>\n      <td>MAC</td>\n      <td>Not Hispanic or Latino</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>Positive</td>\n      <td>No</td>\n      <td>Permissive</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>72.290001</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>43.705002</td>\n      <td>2.0</td>\n      <td>Other GVHD Prophylaxis</td>\n      <td>No</td>\n      <td>F-F</td>\n      <td>2.0</td>\n      <td>Asian</td>\n      <td>3.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Permissive mismatched</td>\n      <td>Related</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>10.0</td>\n      <td>No_No</td>\n      <td>28.584999</td>\n      <td>28.584999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28802</td>\n      <td>N/A - non-malignant indication</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>No TBI</td>\n      <td>No</td>\n      <td>6.0</td>\n      <td>Bone marrow</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>HIS</td>\n      <td>6.0</td>\n      <td>+/+</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>P/P</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>BM</td>\n      <td>Unknown</td>\n      <td>Unknown</td>\n      <td>Not Hispanic or Latino</td>\n      <td>19.0</td>\n      <td>No</td>\n      <td>Unknown</td>\n      <td>Yes</td>\n      <td>Unknown</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>-1.000000</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>33.997002</td>\n      <td>2.0</td>\n      <td>Cyclophosphamide alone</td>\n      <td>No</td>\n      <td>F-M</td>\n      <td>2.0</td>\n      <td>More than one race</td>\n      <td>0.0</td>\n      <td>90.0</td>\n      <td>No</td>\n      <td>Permissive mismatched</td>\n      <td>Related</td>\n      <td>N/A, Mel not given</td>\n      <td>8.0</td>\n      <td>No</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>10.0</td>\n      <td>No_No</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# CSVファイルを読み込む\ndeath_rate_df = pd.read_csv(csv_file_path)\n\n# \"男平均\" と \"女平均\" の行ごとの平均を計算して新しいカラム \"全平均\" に追加\ndeath_rate_df['全平均'] = death_rate_df[['男平均', '女平均']].mean(axis=1)\n\n# '男平均', '女平均', '全平均'の累積和カラムを作成\ndeath_rate_df['男平均_累積和'] = death_rate_df['男平均'].cumsum()\ndeath_rate_df['女平均_累積和'] = death_rate_df['女平均'].cumsum()\ndeath_rate_df['全平均_累積和'] = death_rate_df['全平均'].cumsum()\n\n# データフレームを表示\ndisplay(death_rate_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:49.379624Z","iopub.execute_input":"2025-02-23T12:36:49.380031Z","iopub.status.idle":"2025-02-23T12:36:49.419979Z","shell.execute_reply.started":"2025-02-23T12:36:49.379994Z","shell.execute_reply":"2025-02-23T12:36:49.418881Z"},"id":"oicgyGp5ngBh","outputId":"8d6a856b-6d1b-4422-b992-f0e24cc90bd4"},"outputs":[{"output_type":"display_data","data":{"text/plain":"      年  齢      男平均      女平均       全平均   男平均_累積和   女平均_累積和    全平均_累積和\n0        0    7.100    5.975    6.5375     7.100     5.975     6.5375\n1      1～4    0.350    0.300    0.3250     7.450     6.275     6.8625\n2      5～9    0.175    0.125    0.1500     7.625     6.400     7.0125\n3    10～14    0.200    0.150    0.1750     7.825     6.550     7.1875\n4    15～19    0.650    0.250    0.4500     8.475     6.800     7.6375\n5    20～24    1.050    0.325    0.6875     9.525     7.125     8.3250\n6    25～29    1.325    0.425    0.8750    10.850     7.550     9.2000\n7    30～34    1.550    0.625    1.0875    12.400     8.175    10.2875\n8    35～39    2.100    0.875    1.4875    14.500     9.050    11.7750\n9    40～44    3.125    1.400    2.2625    17.625    10.450    14.0375\n10   45～49    4.975    2.300    3.6375    22.600    12.750    17.6750\n11   50～54    7.725    3.650    5.6875    30.325    16.400    23.3625\n12   55～59   12.475    6.000    9.2375    42.800    22.400    32.6000\n13   60～64   19.300    9.525   14.4125    62.100    31.925    47.0125\n14   65～69   28.325   14.825   21.5750    90.425    46.750    68.5875\n15   70～74   40.650   23.275   31.9625   131.075    70.025   100.5500\n16   75～79   63.450   40.225   51.8375   194.525   110.250   152.3875\n17   80～84  101.100   70.800   85.9500   295.625   181.050   238.3375\n18   85～89  159.000  123.650  141.3250   454.625   304.700   379.6625\n19   90～94  238.550  196.900  217.7250   693.175   501.600   597.3875\n20   95～99  304.325  262.050  283.1875   997.500   763.650   880.5750\n21  100歳以上  327.025  315.575  321.3000  1324.525  1079.225  1201.8750","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>年  齢</th>\n      <th>男平均</th>\n      <th>女平均</th>\n      <th>全平均</th>\n      <th>男平均_累積和</th>\n      <th>女平均_累積和</th>\n      <th>全平均_累積和</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7.100</td>\n      <td>5.975</td>\n      <td>6.5375</td>\n      <td>7.100</td>\n      <td>5.975</td>\n      <td>6.5375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1～4</td>\n      <td>0.350</td>\n      <td>0.300</td>\n      <td>0.3250</td>\n      <td>7.450</td>\n      <td>6.275</td>\n      <td>6.8625</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5～9</td>\n      <td>0.175</td>\n      <td>0.125</td>\n      <td>0.1500</td>\n      <td>7.625</td>\n      <td>6.400</td>\n      <td>7.0125</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10～14</td>\n      <td>0.200</td>\n      <td>0.150</td>\n      <td>0.1750</td>\n      <td>7.825</td>\n      <td>6.550</td>\n      <td>7.1875</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15～19</td>\n      <td>0.650</td>\n      <td>0.250</td>\n      <td>0.4500</td>\n      <td>8.475</td>\n      <td>6.800</td>\n      <td>7.6375</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>20～24</td>\n      <td>1.050</td>\n      <td>0.325</td>\n      <td>0.6875</td>\n      <td>9.525</td>\n      <td>7.125</td>\n      <td>8.3250</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>25～29</td>\n      <td>1.325</td>\n      <td>0.425</td>\n      <td>0.8750</td>\n      <td>10.850</td>\n      <td>7.550</td>\n      <td>9.2000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30～34</td>\n      <td>1.550</td>\n      <td>0.625</td>\n      <td>1.0875</td>\n      <td>12.400</td>\n      <td>8.175</td>\n      <td>10.2875</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>35～39</td>\n      <td>2.100</td>\n      <td>0.875</td>\n      <td>1.4875</td>\n      <td>14.500</td>\n      <td>9.050</td>\n      <td>11.7750</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>40～44</td>\n      <td>3.125</td>\n      <td>1.400</td>\n      <td>2.2625</td>\n      <td>17.625</td>\n      <td>10.450</td>\n      <td>14.0375</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>45～49</td>\n      <td>4.975</td>\n      <td>2.300</td>\n      <td>3.6375</td>\n      <td>22.600</td>\n      <td>12.750</td>\n      <td>17.6750</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>50～54</td>\n      <td>7.725</td>\n      <td>3.650</td>\n      <td>5.6875</td>\n      <td>30.325</td>\n      <td>16.400</td>\n      <td>23.3625</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>55～59</td>\n      <td>12.475</td>\n      <td>6.000</td>\n      <td>9.2375</td>\n      <td>42.800</td>\n      <td>22.400</td>\n      <td>32.6000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>60～64</td>\n      <td>19.300</td>\n      <td>9.525</td>\n      <td>14.4125</td>\n      <td>62.100</td>\n      <td>31.925</td>\n      <td>47.0125</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>65～69</td>\n      <td>28.325</td>\n      <td>14.825</td>\n      <td>21.5750</td>\n      <td>90.425</td>\n      <td>46.750</td>\n      <td>68.5875</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>70～74</td>\n      <td>40.650</td>\n      <td>23.275</td>\n      <td>31.9625</td>\n      <td>131.075</td>\n      <td>70.025</td>\n      <td>100.5500</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>75～79</td>\n      <td>63.450</td>\n      <td>40.225</td>\n      <td>51.8375</td>\n      <td>194.525</td>\n      <td>110.250</td>\n      <td>152.3875</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>80～84</td>\n      <td>101.100</td>\n      <td>70.800</td>\n      <td>85.9500</td>\n      <td>295.625</td>\n      <td>181.050</td>\n      <td>238.3375</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>85～89</td>\n      <td>159.000</td>\n      <td>123.650</td>\n      <td>141.3250</td>\n      <td>454.625</td>\n      <td>304.700</td>\n      <td>379.6625</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>90～94</td>\n      <td>238.550</td>\n      <td>196.900</td>\n      <td>217.7250</td>\n      <td>693.175</td>\n      <td>501.600</td>\n      <td>597.3875</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>95～99</td>\n      <td>304.325</td>\n      <td>262.050</td>\n      <td>283.1875</td>\n      <td>997.500</td>\n      <td>763.650</td>\n      <td>880.5750</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>100歳以上</td>\n      <td>327.025</td>\n      <td>315.575</td>\n      <td>321.3000</td>\n      <td>1324.525</td>\n      <td>1079.225</td>\n      <td>1201.8750</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"\n# =====================\n# 1) 年齢区分を返す関数\n# =====================\ndef get_age_group(age: float) -> str:\n    \"\"\"\n    death_rate_dfの「年齢」カラムに合わせて、数値ageを区間ラベルに変換する。\n    ただし age == -1 は不明を示すため None を返す。\n    \"\"\"\n    if age == -1:\n        return None\n\n    # 0歳\n    if age == 0:\n        return \"0\"\n    # 1～4歳\n    elif 1 <= age < 5:\n        return \" 1～4\"\n    elif 5 <= age < 10:\n        return \" 5～9\"\n    elif 10 <= age < 15:\n        return \"10～14\"\n    elif 15 <= age < 20:\n        return \"15～19\"\n    elif 20 <= age < 25:\n        return \"20～24\"\n    elif 25 <= age < 30:\n        return \"25～29\"\n    elif 30 <= age < 35:\n        return \"30～34\"\n    elif 35 <= age < 40:\n        return \"35～39\"\n    elif 40 <= age < 45:\n        return \"40～44\"\n    elif 45 <= age < 50:\n        return \"45～49\"\n    elif 50 <= age < 55:\n        return \"50～54\"\n    elif 55 <= age < 60:\n        return \"55～59\"\n    elif 60 <= age < 65:\n        return \"60～64\"\n    elif 65 <= age < 70:\n        return \"65～69\"\n    elif 70 <= age < 75:\n        return \"70～74\"\n    elif 75 <= age < 80:\n        return \"75～79\"\n    elif 80 <= age < 85:\n        return \"80～84\"\n    elif 85 <= age < 90:\n        return \"85～89\"\n    elif 90 <= age < 95:\n        return \"90～94\"\n    elif 95 <= age < 100:\n        return \"95～99\"\n    else:\n        # 100歳以上\n        return \"100歳以上\"\n\n\n# =====================\n# 2) sex_match から性別を取り出す関数\n# =====================\ndef get_donor_sex(sex_match: str) -> str:\n    \"\"\"\n    sex_match: \"M-F\" のような文字列\n       → ドナーの性別(M/F)を返す\n    sex_matchがNaNなど不正ならNoneを返す(= 性別不明)\n    \"\"\"\n    if pd.isnull(sex_match):\n        return None\n    parts = sex_match.split(\"-\")\n    if len(parts) == 2:\n        return parts[0].strip()  # ドナー側\n    return None\n\ndef get_recipient_sex(sex_match: str) -> str:\n    \"\"\"\n    sex_match: \"M-F\" のような文字列\n       → レシピエントの性別(M/F)を返す\n    sex_matchがNaNなど不正ならNoneを返す(= 性別不明)\n    \"\"\"\n    if pd.isnull(sex_match):\n        return None\n    parts = sex_match.split(\"-\")\n    if len(parts) == 2:\n        return parts[1].strip()  # レシピエント側\n    return None\n\n\n# =====================\n# 3) death_rate_df を辞書化: { age_label: {\"M\": male, \"F\": female, \"All\": overall}, ... }\n# =====================\ndeath_rate_dict = {}\nfor _, row in death_rate_df.iterrows():\n    age_label = row[\"年  齢\"]        # \"0\", \"1～4\", \"5～9\", ... \"100歳以上\"\n    male_rate = row[\"男平均\"]     # float\n    female_rate = row[\"女平均\"]   # float\n    all_rate   = row[\"全平均\"]    # float\n    cum_male_rate = row[\"男平均_累積和\"]     # float\n    cum_female_rate = row[\"女平均_累積和\"]   # float\n    cum_all_rate   = row[\"全平均_累積和\"]    # float\n    death_rate_dict[age_label] = {\n        \"M\": (male_rate, cum_male_rate),\n        \"F\": (female_rate, cum_female_rate),\n        \"All\": (all_rate, cum_all_rate)\n    }\n\n\n# =====================\n# 4) (年齢, 性別) から死亡率を取得する関数\n# =====================\ndef get_death_rate(age: float, sex: str) -> float:\n    \"\"\"\n    入力:\n      age: 年齢 (ドナー or レシピエントの年齢)\n      sex: 'M' または 'F'、またはNone (不明)\n    戻り値:\n      death_rate: floatまたは np.nan\n    \"\"\"\n    # まず「ageが-1」(不明)なら np.nanを返す\n    if age == -1:\n        return np.nan\n\n    # 年齢区分を取得\n    age_label = get_age_group(age)\n    if (age_label is None) or (age_label not in death_rate_dict):\n        # 万が一該当しない場合は np.nan でも良いが、\n        # ここでは \"100歳以上\" の全平均を返す等、運用次第で対応を変えてください。\n        return np.nan\n\n    # 性別が不明(None)なら全平均を返す\n    if sex is None:\n        return death_rate_dict[age_label][\"All\"][0]\n\n    # 性別が \"M\" または \"F\" なら対応する死亡率を返す\n    if sex == \"M\":\n        return death_rate_dict[age_label][\"M\"][0]\n    elif sex == \"F\":\n        return death_rate_dict[age_label][\"F\"][0]\n    else:\n        # 想定外の文字が入っている場合も全平均にフォールバック (例)\n        return death_rate_dict[age_label][\"All\"][0]\n\n# =====================\n# 4) (年齢, 性別) から累積死亡率を取得する関数\n# =====================\ndef get_cum_death_rate(age: float, sex: str) -> float:\n    \"\"\"\n    入力:\n      age: 年齢 (ドナー or レシピエントの年齢)\n      sex: 'M' または 'F'、またはNone (不明)\n    戻り値:\n      death_rate: floatまたは np.nan\n    \"\"\"\n    # まず「ageが-1」(不明)なら np.nanを返す\n    if age == -1:\n        return np.nan\n\n    # 年齢区分を取得\n    age_label = get_age_group(age)\n    if (age_label is None) or (age_label not in death_rate_dict):\n        # 万が一該当しない場合は np.nan でも良いが、\n        # ここでは \"100歳以上\" の全平均を返す等、運用次第で対応を変えてください。\n        return np.nan\n\n    # 性別が不明(None)なら全平均を返す\n    if sex is None:\n        return death_rate_dict[age_label][\"All\"][1]\n\n    # 性別が \"M\" または \"F\" なら対応する死亡率を返す\n    if sex == \"M\":\n        return death_rate_dict[age_label][\"M\"][1]\n    elif sex == \"F\":\n        return death_rate_dict[age_label][\"F\"][1]\n    else:\n        # 想定外の文字が入っている場合も全平均にフォールバック (例)\n        return death_rate_dict[age_label][\"All\"][1]\n\n\n# =====================\n# 5) train_data, test_data に新カラムを追加\n# =====================\n# ドナーの死亡率\ntrain_data[\"donor_age_death_rate\"] = train_data.apply(\n    lambda row: get_death_rate(row[\"donor_age\"], get_donor_sex(row[\"sex_match\"])), axis=1\n)\n\ntrain_data[\"cum_donor_age_death_rate\"] = train_data.apply(\n    lambda row: get_cum_death_rate(row[\"donor_age\"], get_donor_sex(row[\"sex_match\"])), axis=1\n)\n# レシピエントの死亡率\ntrain_data[\"recipient_age_death_rate\"] = train_data.apply(\n    lambda row: get_death_rate(row[\"age_at_hct\"], get_recipient_sex(row[\"sex_match\"])), axis=1\n)\n\ntrain_data[\"cum_recipient_age_death_rate\"] = train_data.apply(\n    lambda row: get_cum_death_rate(row[\"age_at_hct\"], get_recipient_sex(row[\"sex_match\"])), axis=1\n)\n\n# test_data も同様\ntest_data[\"donor_age_death_rate\"] = test_data.apply(\n    lambda row: get_death_rate(row[\"donor_age\"], get_donor_sex(row[\"sex_match\"])), axis=1\n)\n\ntest_data[\"cum_donor_age_death_rate\"] = test_data.apply(\n    lambda row: get_cum_death_rate(row[\"donor_age\"], get_donor_sex(row[\"sex_match\"])), axis=1)\n\n\ntest_data[\"recipient_age_death_rate\"] = test_data.apply(\n    lambda row: get_death_rate(row[\"age_at_hct\"], get_recipient_sex(row[\"sex_match\"])), axis=1\n)\n\ntest_data[\"cum_recipient_age_death_rate\"] = test_data.apply(\n    lambda row: get_cum_death_rate(row[\"age_at_hct\"], get_recipient_sex(row[\"sex_match\"])), axis=1\n)\n\n# # 新しい特徴量を作成して欠損値を判定\n# train_data['recipient_age_death_rate_is_na'] = train_data['recipient_age_death_rate'].isna().astype(int)\n# train_data['donor_age_death_rate_is_na'] = train_data['donor_age_death_rate'].isna().astype(int)\n\n# test_data['recipient_age_death_rate_is_na'] = test_data['recipient_age_death_rate'].isna().astype(int)\n# test_data['donor_age_death_rate_is_na'] = test_data['donor_age_death_rate'].isna().astype(int)\n\n# recipient_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntrain_data['recipient_age_death_rate'] = train_data['recipient_age_death_rate'].fillna(train_data['recipient_age_death_rate'].mean())\n\n# donor_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntrain_data['donor_age_death_rate'] = train_data['donor_age_death_rate'].fillna(train_data['donor_age_death_rate'].mean())\n\n# recipient_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntest_data['recipient_age_death_rate'] = test_data['recipient_age_death_rate'].fillna(test_data['recipient_age_death_rate'].mean())\n\n# donor_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntest_data['donor_age_death_rate'] = test_data['donor_age_death_rate'].fillna(test_data['donor_age_death_rate'].mean())\n\n# recipient_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntrain_data['cum_recipient_age_death_rate'] = train_data['cum_recipient_age_death_rate'].fillna(train_data['recipient_age_death_rate'].mean())\n\n# donor_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntrain_data['cum_donor_age_death_rate'] = train_data['cum_donor_age_death_rate'].fillna(train_data['donor_age_death_rate'].mean())\n\n# recipient_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntest_data['cum_recipient_age_death_rate'] = test_data['cum_recipient_age_death_rate'].fillna(test_data['recipient_age_death_rate'].mean())\n\n# donor_age_death_rate の NaN を同じカラムの NaN 以外の平均値で埋める\ntest_data['cum_donor_age_death_rate'] = test_data['cum_donor_age_death_rate'].fillna(test_data['donor_age_death_rate'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:49.421179Z","iopub.execute_input":"2025-02-23T12:36:49.421538Z","iopub.status.idle":"2025-02-23T12:36:50.948340Z","shell.execute_reply.started":"2025-02-23T12:36:49.421510Z","shell.execute_reply":"2025-02-23T12:36:50.946844Z"},"id":"7WyaZlgdngBh"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"display(train_data.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:50.949682Z","iopub.execute_input":"2025-02-23T12:36:50.950138Z","iopub.status.idle":"2025-02-23T12:36:51.074208Z","shell.execute_reply.started":"2025-02-23T12:36:50.950097Z","shell.execute_reply":"2025-02-23T12:36:51.072872Z"},"id":"DyEtS160ngBh","outputId":"d75a262c-09ab-4491-aaf1-5bb57913882e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"                 ID  hla_match_c_high  hla_high_res_8  hla_low_res_6  \\\ncount  28800.000000      28800.000000    28800.000000   28800.000000   \nmean   14399.500000          1.321042        5.897570       4.691875   \nstd     8313.988213          1.089035        2.581069       1.769359   \nmin        0.000000         -1.000000        0.000000       0.000000   \n25%     7199.750000          1.000000        4.000000       3.000000   \n50%    14399.500000          2.000000        7.000000       6.000000   \n75%    21599.250000          2.000000        8.000000       6.000000   \nmax    28799.000000          2.000000        8.000000       6.000000   \n\n       hla_high_res_6  hla_high_res_10  hla_match_dqb1_high    hla_nmdp_6  \\\ncount    28800.000000     28800.000000         28800.000000  28800.000000   \nmean         4.416111         7.320903             1.242813      4.642431   \nstd          1.938318         3.153944             1.128069      1.773606   \nmin          0.000000         0.000000            -1.000000      0.000000   \n25%          3.000000         5.000000             1.000000      3.000000   \n50%          5.000000         9.000000             2.000000      6.000000   \n75%          6.000000        10.000000             2.000000      6.000000   \nmax          6.000000        10.000000             2.000000      6.000000   \n\n       hla_match_c_low  hla_match_drb1_low  hla_match_dqb1_low      year_hct  \\\ncount     28800.000000        28800.000000        28800.000000  28800.000000   \nmean          1.489687            1.466111            1.369861     15.179444   \nstd           0.915822            0.894156            1.055029      3.153847   \nmin          -1.000000           -1.000000           -1.000000      8.000000   \n25%           1.000000            1.000000            1.000000     13.000000   \n50%           2.000000            2.000000            2.000000     16.000000   \n75%           2.000000            2.000000            2.000000     18.000000   \nmax           2.000000            2.000000            2.000000     20.000000   \n\n       hla_match_a_high     donor_age  hla_match_b_low    age_at_hct  \\\ncount      28800.000000  28800.000000     28800.000000  28800.000000   \nmean           1.299965     39.780029         1.477674     38.663158   \nstd            1.053784     18.149313         0.887930     21.147446   \nmin           -1.000000     -1.000000        -1.000000      0.044000   \n25%            1.000000     26.898001         1.000000     19.539000   \n50%            2.000000     38.241001         2.000000     41.006001   \n75%            2.000000     55.116001         2.000000     55.965250   \nmax            2.000000     84.800003         2.000000     73.725998   \n\n       hla_match_a_low  hla_match_b_high  comorbidity_score  karnofsky_score  \\\ncount     28800.000000      28800.000000       28800.000000     28800.000000   \nmean          1.484271          1.316424           1.657569        81.269447   \nstd           0.866572          1.035896           2.007735        18.131237   \nmin          -1.000000         -1.000000          -1.000000        -1.000000   \n25%           1.000000          1.000000           0.000000        70.000000   \n50%           2.000000          2.000000           1.000000        90.000000   \n75%           2.000000          2.000000           2.000000        90.000000   \nmax           2.000000          2.000000          10.000000       100.000000   \n\n       hla_low_res_8  hla_match_drb1_high  hla_low_res_10           efs  \\\ncount   28800.000000         28800.000000    28800.000000  28800.000000   \nmean        6.278785             1.392049        7.794271      0.539306   \nstd         2.327928             0.970314        2.858779      0.498514   \nmin         0.000000            -1.000000        0.000000      0.000000   \n25%         4.000000             1.000000        6.000000      0.000000   \n50%         8.000000             2.000000        9.000000      1.000000   \n75%         8.000000             2.000000       10.000000      1.000000   \nmax         8.000000             2.000000       10.000000      1.000000   \n\n           efs_time  age_diff_donor-reci  age_rate_donor-reci  \\\ncount  28800.000000         28800.000000         28800.000000   \nmean      23.237679             2.534599             2.534599   \nstd       24.799696            23.103836            23.103836   \nmin        0.333000           -52.888000           -52.888000   \n25%        5.619750           -12.843500           -12.843500   \n50%        9.796500             0.388000             0.388000   \n75%       35.099998            17.679501            17.679501   \nmax      156.819000            80.768997            80.768997   \n\n       donor_age_death_rate  cum_donor_age_death_rate  \\\ncount          28800.000000              28800.000000   \nmean               5.714956                 22.081755   \nstd                7.963808                 23.489441   \nmin                0.250000                  5.714956   \n25%                1.050000                  9.050000   \n50%                2.100000                 12.400000   \n75%                6.000000                 22.600000   \nmax              101.100000                295.625000   \n\n       recipient_age_death_rate  cum_recipient_age_death_rate  \ncount              28800.000000                  28800.000000  \nmean                  22.084072                     83.971775  \nstd                   69.441737                    260.049517  \nmin                    0.125000                      6.275000  \n25%                    0.650000                      8.475000  \n50%                    3.125000                     16.400000  \n75%                    9.525000                     31.925000  \nmax                  327.025000                   1324.525000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>hla_match_c_high</th>\n      <th>hla_high_res_8</th>\n      <th>hla_low_res_6</th>\n      <th>hla_high_res_6</th>\n      <th>hla_high_res_10</th>\n      <th>hla_match_dqb1_high</th>\n      <th>hla_nmdp_6</th>\n      <th>hla_match_c_low</th>\n      <th>hla_match_drb1_low</th>\n      <th>hla_match_dqb1_low</th>\n      <th>year_hct</th>\n      <th>hla_match_a_high</th>\n      <th>donor_age</th>\n      <th>hla_match_b_low</th>\n      <th>age_at_hct</th>\n      <th>hla_match_a_low</th>\n      <th>hla_match_b_high</th>\n      <th>comorbidity_score</th>\n      <th>karnofsky_score</th>\n      <th>hla_low_res_8</th>\n      <th>hla_match_drb1_high</th>\n      <th>hla_low_res_10</th>\n      <th>efs</th>\n      <th>efs_time</th>\n      <th>age_diff_donor-reci</th>\n      <th>age_rate_donor-reci</th>\n      <th>donor_age_death_rate</th>\n      <th>cum_donor_age_death_rate</th>\n      <th>recipient_age_death_rate</th>\n      <th>cum_recipient_age_death_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n      <td>28800.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14399.500000</td>\n      <td>1.321042</td>\n      <td>5.897570</td>\n      <td>4.691875</td>\n      <td>4.416111</td>\n      <td>7.320903</td>\n      <td>1.242813</td>\n      <td>4.642431</td>\n      <td>1.489687</td>\n      <td>1.466111</td>\n      <td>1.369861</td>\n      <td>15.179444</td>\n      <td>1.299965</td>\n      <td>39.780029</td>\n      <td>1.477674</td>\n      <td>38.663158</td>\n      <td>1.484271</td>\n      <td>1.316424</td>\n      <td>1.657569</td>\n      <td>81.269447</td>\n      <td>6.278785</td>\n      <td>1.392049</td>\n      <td>7.794271</td>\n      <td>0.539306</td>\n      <td>23.237679</td>\n      <td>2.534599</td>\n      <td>2.534599</td>\n      <td>5.714956</td>\n      <td>22.081755</td>\n      <td>22.084072</td>\n      <td>83.971775</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8313.988213</td>\n      <td>1.089035</td>\n      <td>2.581069</td>\n      <td>1.769359</td>\n      <td>1.938318</td>\n      <td>3.153944</td>\n      <td>1.128069</td>\n      <td>1.773606</td>\n      <td>0.915822</td>\n      <td>0.894156</td>\n      <td>1.055029</td>\n      <td>3.153847</td>\n      <td>1.053784</td>\n      <td>18.149313</td>\n      <td>0.887930</td>\n      <td>21.147446</td>\n      <td>0.866572</td>\n      <td>1.035896</td>\n      <td>2.007735</td>\n      <td>18.131237</td>\n      <td>2.327928</td>\n      <td>0.970314</td>\n      <td>2.858779</td>\n      <td>0.498514</td>\n      <td>24.799696</td>\n      <td>23.103836</td>\n      <td>23.103836</td>\n      <td>7.963808</td>\n      <td>23.489441</td>\n      <td>69.441737</td>\n      <td>260.049517</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>8.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.044000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333000</td>\n      <td>-52.888000</td>\n      <td>-52.888000</td>\n      <td>0.250000</td>\n      <td>5.714956</td>\n      <td>0.125000</td>\n      <td>6.275000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7199.750000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>13.000000</td>\n      <td>1.000000</td>\n      <td>26.898001</td>\n      <td>1.000000</td>\n      <td>19.539000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>70.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>5.619750</td>\n      <td>-12.843500</td>\n      <td>-12.843500</td>\n      <td>1.050000</td>\n      <td>9.050000</td>\n      <td>0.650000</td>\n      <td>8.475000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>14399.500000</td>\n      <td>2.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>9.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>16.000000</td>\n      <td>2.000000</td>\n      <td>38.241001</td>\n      <td>2.000000</td>\n      <td>41.006001</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>90.000000</td>\n      <td>8.000000</td>\n      <td>2.000000</td>\n      <td>9.000000</td>\n      <td>1.000000</td>\n      <td>9.796500</td>\n      <td>0.388000</td>\n      <td>0.388000</td>\n      <td>2.100000</td>\n      <td>12.400000</td>\n      <td>3.125000</td>\n      <td>16.400000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>21599.250000</td>\n      <td>2.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>10.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>18.000000</td>\n      <td>2.000000</td>\n      <td>55.116001</td>\n      <td>2.000000</td>\n      <td>55.965250</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>90.000000</td>\n      <td>8.000000</td>\n      <td>2.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n      <td>35.099998</td>\n      <td>17.679501</td>\n      <td>17.679501</td>\n      <td>6.000000</td>\n      <td>22.600000</td>\n      <td>9.525000</td>\n      <td>31.925000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>28799.000000</td>\n      <td>2.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>10.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>20.000000</td>\n      <td>2.000000</td>\n      <td>84.800003</td>\n      <td>2.000000</td>\n      <td>73.725998</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>10.000000</td>\n      <td>100.000000</td>\n      <td>8.000000</td>\n      <td>2.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n      <td>156.819000</td>\n      <td>80.768997</td>\n      <td>80.768997</td>\n      <td>101.100000</td>\n      <td>295.625000</td>\n      <td>327.025000</td>\n      <td>1324.525000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"display(test_data.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.075688Z","iopub.execute_input":"2025-02-23T12:36:51.076162Z","iopub.status.idle":"2025-02-23T12:36:51.087137Z","shell.execute_reply.started":"2025-02-23T12:36:51.076111Z","shell.execute_reply":"2025-02-23T12:36:51.085679Z"},"id":"DSNKBhlsngBh","outputId":"be92e448-f78a-42db-fce6-81fed3b41ab6"},"outputs":[{"output_type":"display_data","data":{"text/plain":"ID                                int32\ndri_score                        object\npsych_disturb                    object\ncyto_score                       object\ndiabetes                         object\nhla_match_c_high                float32\nhla_high_res_8                  float32\ntbi_status                       object\narrhythmia                       object\nhla_low_res_6                   float32\ngraft_type                       object\nvent_hist                        object\nrenal_issue                      object\npulm_severe                      object\nprim_disease_hct                 object\nhla_high_res_6                  float32\ncmv_status                       object\nhla_high_res_10                 float32\nhla_match_dqb1_high             float32\ntce_imm_match                    object\nhla_nmdp_6                      float32\nhla_match_c_low                 float32\nrituximab                        object\nhla_match_drb1_low              float32\nhla_match_dqb1_low              float32\nprod_type                        object\ncyto_score_detail                object\nconditioning_intensity           object\nethnicity                        object\nyear_hct                        float32\nobesity                          object\nmrd_hct                          object\nin_vivo_tcd                      object\ntce_match                        object\nhla_match_a_high                float32\nhepatic_severe                   object\ndonor_age                       float32\nprior_tumor                      object\nhla_match_b_low                 float32\npeptic_ulcer                     object\nage_at_hct                      float32\nhla_match_a_low                 float32\ngvhd_proph                       object\nrheum_issue                      object\nsex_match                        object\nhla_match_b_high                float32\nrace_group                       object\ncomorbidity_score               float32\nkarnofsky_score                 float32\nhepatic_mild                     object\ntce_div_match                    object\ndonor_related                    object\nmelphalan_dose                   object\nhla_low_res_8                   float32\ncardiac                          object\nhla_match_drb1_high             float32\npulm_moderate                    object\nhla_low_res_10                  float32\ndiabetes_obesity                 object\nage_diff_donor-reci             float32\nage_rate_donor-reci             float32\ndonor_age_death_rate            float64\ncum_donor_age_death_rate        float64\nrecipient_age_death_rate        float64\ncum_recipient_age_death_rate    float64\ndtype: object"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"display(train_data.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.088553Z","iopub.execute_input":"2025-02-23T12:36:51.088995Z","iopub.status.idle":"2025-02-23T12:36:51.110532Z","shell.execute_reply.started":"2025-02-23T12:36:51.088947Z","shell.execute_reply":"2025-02-23T12:36:51.108977Z"},"id":"s7tIaOjqngBh","outputId":"ec684a7b-c2b1-492c-daf6-91e3749f6dcd"},"outputs":[{"output_type":"display_data","data":{"text/plain":"ID                                int32\ndri_score                        object\npsych_disturb                    object\ncyto_score                       object\ndiabetes                         object\nhla_match_c_high                float32\nhla_high_res_8                  float32\ntbi_status                       object\narrhythmia                       object\nhla_low_res_6                   float32\ngraft_type                       object\nvent_hist                        object\nrenal_issue                      object\npulm_severe                      object\nprim_disease_hct                 object\nhla_high_res_6                  float32\ncmv_status                       object\nhla_high_res_10                 float32\nhla_match_dqb1_high             float32\ntce_imm_match                    object\nhla_nmdp_6                      float32\nhla_match_c_low                 float32\nrituximab                        object\nhla_match_drb1_low              float32\nhla_match_dqb1_low              float32\nprod_type                        object\ncyto_score_detail                object\nconditioning_intensity           object\nethnicity                        object\nyear_hct                        float32\nobesity                          object\nmrd_hct                          object\nin_vivo_tcd                      object\ntce_match                        object\nhla_match_a_high                float32\nhepatic_severe                   object\ndonor_age                       float32\nprior_tumor                      object\nhla_match_b_low                 float32\npeptic_ulcer                     object\nage_at_hct                      float32\nhla_match_a_low                 float32\ngvhd_proph                       object\nrheum_issue                      object\nsex_match                        object\nhla_match_b_high                float32\nrace_group                       object\ncomorbidity_score               float32\nkarnofsky_score                 float32\nhepatic_mild                     object\ntce_div_match                    object\ndonor_related                    object\nmelphalan_dose                   object\nhla_low_res_8                   float32\ncardiac                          object\nhla_match_drb1_high             float32\npulm_moderate                    object\nhla_low_res_10                  float32\nefs                             float32\nefs_time                        float32\ndiabetes_obesity                 object\nage_diff_donor-reci             float32\nage_rate_donor-reci             float32\ndonor_age_death_rate            float64\ncum_donor_age_death_rate        float64\nrecipient_age_death_rate        float64\ncum_recipient_age_death_rate    float64\ndtype: object"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"nan_counts = train_data.isna().sum()\nnan_columns = nan_counts[nan_counts > 0]\nprint(\"NaNが存在するカラムとその数:\")\nprint(nan_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.111868Z","iopub.execute_input":"2025-02-23T12:36:51.112314Z","iopub.status.idle":"2025-02-23T12:36:51.194844Z","shell.execute_reply.started":"2025-02-23T12:36:51.112269Z","shell.execute_reply":"2025-02-23T12:36:51.193633Z"},"id":"p3RxyN0ingBh","outputId":"62e7b371-68fd-4f6d-eb8f-c6b378a5c4c8"},"outputs":[{"name":"stdout","text":"NaNが存在するカラムとその数:\nSeries([], dtype: int64)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"nan_counts = test_data.isna().sum()\nnan_columns = nan_counts[nan_counts > 0]\nprint(\"NaNが存在するカラムとその数:\")\nprint(nan_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.196112Z","iopub.execute_input":"2025-02-23T12:36:51.196496Z","iopub.status.idle":"2025-02-23T12:36:51.205222Z","shell.execute_reply.started":"2025-02-23T12:36:51.196456Z","shell.execute_reply":"2025-02-23T12:36:51.203755Z"},"id":"tL6TXJ8JngBi","outputId":"828425e0-cea5-4a5b-8a36-31b43594d16d"},"outputs":[{"name":"stdout","text":"NaNが存在するカラムとその数:\nSeries([], dtype: int64)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"nan_records = test_data[test_data['donor_age_death_rate'].isna() | test_data['recipient_age_death_rate'].isna()]\n# nan_records = train_data[train_data['donor_age_death_rate'].isna() | train_data['recipient_age_death_rate'].isna()]\n# \"donor_age_death_rate\" が NaN のレコードを抽出\n# nan_records = train_data[train_data['donor_age_death_rate'].isna()]\n# nan_records = test_data[train_data['recipient_age_death_rate'].isna()]\n#\n# 結果を表示\ndisplay(nan_records[[\"age_at_hct\",\"donor_age\",\"sex_match\", \"recipient_age_death_rate\", \"donor_age_death_rate\", \"cum_recipient_age_death_rate\", \"cum_donor_age_death_rate\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.210150Z","iopub.execute_input":"2025-02-23T12:36:51.210521Z","iopub.status.idle":"2025-02-23T12:36:51.233121Z","shell.execute_reply.started":"2025-02-23T12:36:51.210491Z","shell.execute_reply":"2025-02-23T12:36:51.231884Z"},"id":"khzn617sngBi","outputId":"6b56cc66-b93a-4150-9076-9e335958a507"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Empty DataFrame\nColumns: [age_at_hct, donor_age, sex_match, recipient_age_death_rate, donor_age_death_rate, cum_recipient_age_death_rate, cum_donor_age_death_rate]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age_at_hct</th>\n      <th>donor_age</th>\n      <th>sex_match</th>\n      <th>recipient_age_death_rate</th>\n      <th>donor_age_death_rate</th>\n      <th>cum_recipient_age_death_rate</th>\n      <th>cum_donor_age_death_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"nan_records = train_data[train_data['donor_age_death_rate'].isna() | train_data['recipient_age_death_rate'].isna()|train_data['cum_donor_age_death_rate'].isna() | train_data['cum_recipient_age_death_rate'].isna()]\n# nan_records = train_data[train_data['donor_age_death_rate'].isna() | train_data['recipient_age_death_rate'].isna()]\n# \"donor_age_death_rate\" が NaN のレコードを抽出\n# nan_records = train_data[train_data['donor_age_death_rate'].isna()]\n# nan_records = train_data[train_data['recipient_age_death_rate'].isna()]\n\n# 結果を表示\ndisplay(nan_records[[\"age_at_hct\",\"donor_age\",\"sex_match\", \"recipient_age_death_rate\", \"donor_age_death_rate\", \"cum_recipient_age_death_rate\", \"cum_donor_age_death_rate\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.235087Z","iopub.execute_input":"2025-02-23T12:36:51.235419Z","iopub.status.idle":"2025-02-23T12:36:51.260432Z","shell.execute_reply.started":"2025-02-23T12:36:51.235393Z","shell.execute_reply":"2025-02-23T12:36:51.258962Z"},"id":"_IkqpKkUngBi","outputId":"3bca4134-40d5-4c7f-cec5-38d1a3ece255"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Empty DataFrame\nColumns: [age_at_hct, donor_age, sex_match, recipient_age_death_rate, donor_age_death_rate, cum_recipient_age_death_rate, cum_donor_age_death_rate]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age_at_hct</th>\n      <th>donor_age</th>\n      <th>sex_match</th>\n      <th>recipient_age_death_rate</th>\n      <th>donor_age_death_rate</th>\n      <th>cum_recipient_age_death_rate</th>\n      <th>cum_donor_age_death_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"display(train_data[[\"age_at_hct\",\"donor_age\",\"sex_match\", \"recipient_age_death_rate\", \"donor_age_death_rate\", \"cum_recipient_age_death_rate\", \"cum_donor_age_death_rate\"]].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.261960Z","iopub.execute_input":"2025-02-23T12:36:51.262320Z","iopub.status.idle":"2025-02-23T12:36:51.282575Z","shell.execute_reply.started":"2025-02-23T12:36:51.262291Z","shell.execute_reply":"2025-02-23T12:36:51.281143Z"},"id":"CVqxpFU9ngBi","outputId":"1364c1f4-9de5-4003-e793-2a7f054d99ef"},"outputs":[{"output_type":"display_data","data":{"text/plain":"   age_at_hct  donor_age sex_match  recipient_age_death_rate  \\\n0    9.942000  -1.000000       M-F                     0.125   \n1   43.705002  72.290001       F-F                     1.400   \n2   33.997002  -1.000000       F-M                     1.550   \n3   43.244999  29.230000       M-M                     3.125   \n4   29.740000  56.810001       M-F                     0.425   \n\n   donor_age_death_rate  cum_recipient_age_death_rate  \\\n0              5.714956                         6.400   \n1             23.275000                        10.450   \n2              5.714956                        12.400   \n3              1.325000                        17.625   \n4             12.475000                         7.550   \n\n   cum_donor_age_death_rate  \n0                  5.714956  \n1                 70.025000  \n2                  5.714956  \n3                 10.850000  \n4                 42.800000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age_at_hct</th>\n      <th>donor_age</th>\n      <th>sex_match</th>\n      <th>recipient_age_death_rate</th>\n      <th>donor_age_death_rate</th>\n      <th>cum_recipient_age_death_rate</th>\n      <th>cum_donor_age_death_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.942000</td>\n      <td>-1.000000</td>\n      <td>M-F</td>\n      <td>0.125</td>\n      <td>5.714956</td>\n      <td>6.400</td>\n      <td>5.714956</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>43.705002</td>\n      <td>72.290001</td>\n      <td>F-F</td>\n      <td>1.400</td>\n      <td>23.275000</td>\n      <td>10.450</td>\n      <td>70.025000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33.997002</td>\n      <td>-1.000000</td>\n      <td>F-M</td>\n      <td>1.550</td>\n      <td>5.714956</td>\n      <td>12.400</td>\n      <td>5.714956</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>43.244999</td>\n      <td>29.230000</td>\n      <td>M-M</td>\n      <td>3.125</td>\n      <td>1.325000</td>\n      <td>17.625</td>\n      <td>10.850000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.740000</td>\n      <td>56.810001</td>\n      <td>M-F</td>\n      <td>0.425</td>\n      <td>12.475000</td>\n      <td>7.550</td>\n      <td>42.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# print(nan_records[\"donor_age_death_rate\"].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.284441Z","iopub.execute_input":"2025-02-23T12:36:51.285003Z","iopub.status.idle":"2025-02-23T12:36:51.290321Z","shell.execute_reply.started":"2025-02-23T12:36:51.284952Z","shell.execute_reply":"2025-02-23T12:36:51.289131Z"},"id":"aHXntoYjngBi"},"outputs":[],"execution_count":29},{"cell_type":"code","source":"display(train_data[[\"age_at_hct\",\"donor_age\",\"sex_match\", \"recipient_age_death_rate\", \"donor_age_death_rate\", \"cum_recipient_age_death_rate\", \"cum_donor_age_death_rate\"]].info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.291681Z","iopub.execute_input":"2025-02-23T12:36:51.291989Z","iopub.status.idle":"2025-02-23T12:36:51.327313Z","shell.execute_reply.started":"2025-02-23T12:36:51.291962Z","shell.execute_reply":"2025-02-23T12:36:51.326023Z"},"id":"SiYKWdiungBi","outputId":"ff83c8bf-f5a4-4616-f181-0b6891d05b09"},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 28800 entries, 0 to 28799\nData columns (total 7 columns):\n #   Column                        Non-Null Count  Dtype  \n---  ------                        --------------  -----  \n 0   age_at_hct                    28800 non-null  float32\n 1   donor_age                     28800 non-null  float32\n 2   sex_match                     28800 non-null  object \n 3   recipient_age_death_rate      28800 non-null  float64\n 4   donor_age_death_rate          28800 non-null  float64\n 5   cum_recipient_age_death_rate  28800 non-null  float64\n 6   cum_donor_age_death_rate      28800 non-null  float64\ndtypes: float32(2), float64(4), object(1)\nmemory usage: 1.3+ MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# データフレームを表示\n# display(death_rate_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.328268Z","iopub.execute_input":"2025-02-23T12:36:51.328546Z","iopub.status.idle":"2025-02-23T12:36:51.333332Z","shell.execute_reply.started":"2025-02-23T12:36:51.328522Z","shell.execute_reply":"2025-02-23T12:36:51.331760Z"},"id":"RfoJcIgangBi"},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Model Development</p>","metadata":{"papermill":{"duration":0.009157,"end_time":"2024-12-13T13:23:12.246272","exception":false,"start_time":"2024-12-13T13:23:12.237115","status":"completed"},"tags":[],"id":"2kCGF0KlngBi"}},{"cell_type":"code","source":"import plotly.express as px\nfrom IPython.display import display\n\nclass EDA:\n\n    def __init__(self, color, data):\n        self._color = color\n        self.data = data\n\n    def _template(self, fig, title):\n\n        fig.update_layout(\n            title=title,\n            title_x=0.5,\n            plot_bgcolor='rgba(247, 230, 202, 1)',\n            paper_bgcolor='rgba(247, 230, 202, 1)',\n            font=dict(color=self._color),\n            margin=dict(l=72, r=72, t=72, b=72),\n            height=720\n        )\n\n        return fig\n\n\n    # Plotly Expressを使用してヒストグラムを作成し、そのレイアウトとトレースをカスタマイズ\ndef distribution_plot(self, col, title):\n    # 全体のヒストグラム\n    fig1 = px.histogram(\n        self.data,\n        x=col,\n        nbins=100,\n        color_discrete_sequence=[self._color]\n    )\n    fig1.update_layout(\n        xaxis_title='Values',\n        yaxis_title='Count',\n        bargap=0.1,\n        xaxis=dict(gridcolor='grey'),\n        yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n    )\n    fig1.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n    fig1 = self._template(fig1, f'{title}')\n    display(fig1)\n\n    # efs=0 のデータ\n    fig2 = px.histogram(\n        self.data[self.data['efs'] == 0],\n        x=col,\n        nbins=100,\n        color_discrete_sequence=[self._color]\n    )\n    fig2.update_layout(\n        xaxis_title='Values',\n        yaxis_title='Count',\n        bargap=0.1,\n        xaxis=dict(gridcolor='grey'),\n        yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n    )\n    fig2.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n    fig2 = self._template(fig2, f'{title} - efs=0')\n    display(fig2)\n\n    # efs=1 のデータ\n    fig3 = px.histogram(\n        self.data[self.data['efs'] == 1],\n        x=col,\n        nbins=100,\n        color_discrete_sequence=[self._color]\n    )\n    fig3.update_layout(\n        xaxis_title='Values',\n        yaxis_title='Count',\n        bargap=0.1,\n        xaxis=dict(gridcolor='grey'),\n        yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n    )\n    fig3.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n    fig3 = self._template(fig3, f'{title} - efs=1')\n    display(fig3)\n    \n    return None\n\n    \n#     def distribution_plot(self, col, title):\n\n# #         データの準備:\n# # px.histogramを使ってヒストグラムを作成しています。\n# # self.data: データフレーム。\n# # x=col: ヒストグラムのX軸に使用する列。\n# # nbins=100: ビンの数を100に設定。\n# # color_discrete_sequence=[self._color]: ヒストグラムの色を指定\n\n#         fig1 = px.histogram(\n#             self.data,\n#             x=col,\n#             nbins=100,\n#             color_discrete_sequence=[self._color]\n#         )\n\n\n# #         レイアウトの更新:\n# # fig.update_layoutを使ってヒストグラムのレイアウトをカスタマイズ。\n# # xaxis_title='Values': X軸のタイトル。\n# # yaxis_title='Count': Y軸のタイトル。\n# # bargap=0.1: バー間の隙間を設定。\n# # xaxis.dict(gridcolor='grey')とyaxis.dict(gridcolor='grey', zerolinecolor='grey'): グリッド線とゼロ線の色をグレーに設定。\n\n#         fig1.update_layout(\n#             xaxis_title='Values',\n#             yaxis_title='Count',\n#             bargap=0.1,\n#             xaxis=dict(gridcolor='grey'),\n#             yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n#         )\n\n\n#         # ホバー時の情報をカスタマイズ。\n# # hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}': ホバー時に表示されるテンプレート。\n#         # 「ホバー時」とは、マウスカーソルをグラフ上の特定のデータポイントに重ねたときのことを指します。この操作中に、通常はそのポイントに関連する追加情報（例として、X軸の値やY軸のカウントなど）がポップアップとして表示されます。この情報はデータを視覚的に確認する際に便利です。\n#         fig1.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n\n# #         テンプレートの適用と表示:\n# # self._template(fig, f'{title}')でテンプレートを適用（詳細はself._templateメソッドによる）。\n# # fig.show()でプロットを表示。\n#         fig1 = self._template(fig1, f'{title}')\n#         display(fig1)\n\n        \n#         # `efs=0` のデータでヒストグラムを作成\n#         fig2 = px.histogram(\n#             self.data[self.data['efs'] == 0],  # `efs=0` のデータのみ\n#             x=col,\n#             nbins=100,\n#             color_discrete_sequence=[self._color]\n#         )\n        \n#         fig2.update_layout(\n#             xaxis_title='Values',\n#             yaxis_title='Count',\n#             bargap=0.1,\n#             xaxis=dict(gridcolor='grey'),\n#             yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n#         )\n        \n#         fig2.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n#         fig2 = self._template(fig2, f'{title} - efs=0')\n#         display(fig2)\n        \n        \n#         # `efs=1` のデータでヒストグラムを作成\n#         fig3 = px.histogram(\n#             self.data[self.data['efs'] == 1],  # `efs=1` のデータのみ\n#             x=col,\n#             nbins=100,\n#             color_discrete_sequence=[self._color]\n#         )\n        \n#         fig3.update_layout(\n#             xaxis_title='Values',\n#             yaxis_title='Count',\n#             bargap=0.1,\n#             xaxis=dict(gridcolor='grey'),\n#             yaxis=dict(gridcolor='grey', zerolinecolor='grey')\n#         )\n        \n#         fig3.update_traces(hovertemplate='Value: %{x:.2f}<br>Count: %{y:,}')\n#         fig3 = self._template(fig3, f'{title} - efs=1')\n#         display(fig3)\n\n#         return None\n\n\n\n\n        \n\n    def _plot_cv(self, scores, title, metric='Stratified C-Index'):\n\n        fold_scores = [round(score, 3) for score in scores]\n        mean_score = round(np.mean(scores), 3)\n\n        # で新しいグラフを作成。\n        fig = go.Figure()\n\n        # 折りたたみスコア（クロスバリデーションの各フォールドのスコア）をプロット。\n#         x軸にはフォールド番号（1からスコア数まで）、y軸には該当するスコアを指定。\n# モードは'markers'で、プロットはダイヤ型のマーカーを使用。\n# hovertemplateでホバー時に「Fold x: score」を表示。\n        fig.add_trace(go.Scatter(\n            x = list(range(1, len(fold_scores) + 1)),\n            y = fold_scores,\n            mode = 'markers',\n            name = 'Fold Scores',\n            marker = dict(size = 27, color=self._color, symbol='diamond'),\n            text = [f'{score:.3f}' for score in fold_scores],\n            hovertemplate = 'Fold %{x}: %{text}<extra></extra>',\n            hoverlabel = dict(font=dict(size=18)) # {'font': {'size': 18}}\n        ))\n\n\n        #         平均線の追加:\n# もう一つのトレースを追加し、クロスバリデーションスコアの平均値を示す水平な破線（ダッシュ）をプロット。\n# 平均線にはホバー情報が表示されません。\n        fig.add_trace(go.Scatter(\n            x = [1, len(fold_scores)],\n            y = [mean_score, mean_score],\n            mode = 'lines',\n            name = f'Mean: {mean_score:.3f}',\n            line = dict(dash = 'dash', color = '#B22222'),\n            hoverinfo = 'none'\n        ))\n\n\n# レイアウトの更新:\n# fig.update_layout(...)で全体のレイアウトを調整。\n# グラフのタイトルに平均スコアを含め、X軸およびY軸に適切なタイトルを追加。\n# 背景色や文字色を設定し、グリッド線やゼロ線をグレーにすることで見やすくします。\n# X軸にはフォールドを示す線形タックを設定。\n        fig.update_layout(\n            title = f'{title} | Cross-validation Mean {metric} Score: {mean_score}',\n            xaxis_title = 'Fold',\n            yaxis_title = f'{metric} Score',\n            plot_bgcolor = 'rgba(247, 230, 202, 1)',\n            paper_bgcolor = 'rgba(247, 230, 202, 1)',\n            font = dict(color=self._color),\n            xaxis = dict(\n                gridcolor = 'grey',\n                tickmode = 'linear',\n                tick0 = 1,\n                dtick = 1,\n                range = [0.5, len(fold_scores) + 0.5],\n                zerolinecolor = 'grey'\n            ),\n\n            yaxis = dict(\n                gridcolor = 'grey',\n                zerolinecolor = 'grey'\n            )\n        )\n\n        fig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.334592Z","iopub.execute_input":"2025-02-23T12:36:51.334918Z","iopub.status.idle":"2025-02-23T12:36:51.354851Z","shell.execute_reply.started":"2025-02-23T12:36:51.334892Z","shell.execute_reply":"2025-02-23T12:36:51.353632Z"},"id":"zkEcCb8dngBi"},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"累積ハザード関数の出力は確率そのものではなく、イベントが発生するリスクの累積量です。\n\n### 特徴\n\n1. **リスクの累積量**:\n   - 累積ハザード関数は時間の経過に伴うイベント発生の累積リスクを示します。この値が大きいほど、それまでの時間にイベントが発生するリスクが高いことを示しています。\n\n2. **確率との関係**:\n   - 累積ハザード関数から生存関数（特定の時間までイベントが発生しない確率）を計算できます。生存関数は、累積ハザード関数を用いて次の式で表されます：\n\n   $$ S(t) = e^{-H(t)} $$\n\n   ここで、\\(S(t)\\) は生存関数で、\\(H(t)\\) は累積ハザード関数の値です。このため生存関数は時間とともに減少し、累積したリスクからイベント発生しない確率を導出できます。\n\nしたがって、累積ハザード関数そのものは確率ではありませんが、この関数を使って生存確率などの確率的な指標を導出することができます。","metadata":{"id":"jwoUQrYDngBi"}},{"cell_type":"code","source":"class Targets:\n\n    def __init__(self, data, cat_cols, penalizer, n_splits):\n\n        self.data = data\n        self.cat_cols = cat_cols\n\n        self._length = len(self.data)\n        self._penalizer = penalizer\n        self._n_splits = n_splits\n\n    def _prepare_cv(self):\n\n        oof_preds = np.zeros(self._length)\n\n        cv = KFold(n_splits=self._n_splits, shuffle=True, random_state=42)\n\n        return cv, oof_preds\n\n    def validate_model(self, preds, title):\n\n        y_true = self.data[['ID', 'efs', 'efs_time', 'race_group']].copy()\n        y_pred = self.data[['ID']].copy()\n\n        y_pred['prediction'] = preds\n\n        c_index_score = score(y_true.copy(), y_pred.copy(), 'ID')\n        # print(f'Overall Stratified C-Index Score for {title}: {c_index_score:.4f}')\n\n        return c_index_score\n\n    def create_target1(self, directory_path):\n\n        '''\n        Inside the CV loop, constant columns are dropped if they exist in a fold. Otherwise, the code produces error:\n\n        delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation:\n\n        CVループ内では、もしフォールドに定数列が存在すればそれを削除します。そうしないと、以下のようなエラーが発生します：\n\n「deltaにNaN値が含まれています。収束が停止しました。詳細はlifelinesのドキュメントの次のヒントを参照してください。」\n        https://lifelines.readthedocs.io/en/latest/Examples.html#problems-with-convergence-in-the-cox-proportional-hazard-model\n        '''\n\n        cv, oof_preds = self._prepare_cv()\n\n        # Apply one hot encoding to categorical columns\n        data = pd.get_dummies(self.data, columns=self.cat_cols, drop_first=True).drop('ID', axis=1)\n\n        for fold, (train_index, valid_index) in enumerate(cv.split(data)):\n\n            train_data = data.iloc[train_index]\n            valid_data = data.iloc[valid_index]\n\n            # Drop constant columns if they exist\n            train_data = train_data.loc[:, train_data.nunique() > 1]\n            valid_data = valid_data[train_data.columns]\n\n# CoxPHFitterは、以下の入力を使用して分析を行い、特定の出力を生成します。\n# 入力:\n# 観察時間 (duration_col):\n# 各サンプルのフォローアップ期間や生存時間を示すデータです。\n# イベントが発生したかどうか (event_col):\n# 各サンプルについて、イベント（例えば死亡や故障）が実際に発生したか、打ち切られたかを示す二値データです（1はイベント発生、0は打ち切り）。\n# 共変量:\n# ハザードに影響を与えるとされる変数のセットです。例えば、年齢、性別、治療法など。\n# 出力:\n# ハザード比（係数） :\n# 各共変量が生存に与える影響を推定した係数（ログハザード比）を提供します。この係数は、その変数がハザードにどの程度の影響を与えるかを定量化します。\n# リスク比の解釈:\n# 推定された係数をもとに、共変量がリスクに与える影響（例えば、ある変数が1単位増えるとリスクが何倍になるか）を解釈します。\n# 要約統計量と信頼区間:\n# モデルの適合度や共変量に関する信頼区間、p値などの詳細な統計情報を提供します。\n# 生存関数とハザード関数の予測:\n# 新しいデータに対する予測生存関数や基礎ハザード率を計算することができます。\n# これにより、CoxPHFitterは、異なる共変量が生存時間にどのような影響を及ぼすかを分析し、リスクを定量的に評価することが可能です。\n\n# 学習時\n# --------------------------------------------------------------------------------------\n            cph = CoxPHFitter(penalizer=self._penalizer)\n            cph.fit(train_data, duration_col='efs_time', event_col='efs')\n            # モデルを保存\n            joblib.dump(cph, directory_path / f\"cph_model_fold{fold}.joblib\")\n# -----------------------------------------------------------------------------------------\n# モデルを読み込むとき\n# -----------------------------------------------------------\n            # モデルをロード\n            # cph = joblib.load(f\"cph_model_fold{fold}.joblib\")\n# --------------------------------------------------------------------------------\n\n            oof_preds[valid_index] = cph.predict_partial_hazard(valid_data)\n\n        self.data['target1'] = oof_preds\n        self.validate_model(oof_preds, 'Cox')\n\n        return self.data\n\n    def create_target2(self, directory_path):\n\n        cv, oof_preds = self._prepare_cv()\n\n        for fold, (train_index, valid_index) in enumerate(cv.split(self.data)):\n\n            train_data = self.data.iloc[train_index]\n            valid_data = self.data.iloc[valid_index]\n\n# KaplanMeierFitterを使用すると、特定の時間における生存率を変数として取得することができます。\n            # 学習時\n# --------------------------------------------------------------------------------------\n            kmf = KaplanMeierFitter()\n            kmf.fit(durations=train_data['efs_time'], event_observed=train_data['efs'])\n\n            # モデルを保存\n            joblib.dump(kmf, directory_path / f\"kmf_model_fold{fold}.joblib\")\n# -----------------------------------------------------------------------------------------\n# モデルを読み込むとき\n# -----------------------------------------------------------\n            # モデルをロード\n            # kmf = joblib.load(f\"kmf_model_fold{fold}.joblib\")\n# --------------------------------------------------------------------------------\n\n            # 検証データ（valid_data）の特定の時間における生存率を予測し、それを配列oof_predsのvalid_index位置に格納\n            oof_preds[valid_index] = kmf.survival_function_at_times(valid_data['efs_time']).values\n\n        self.data['target2'] = oof_preds\n        self.validate_model(oof_preds, 'Kaplan-Meier')\n\n        return self.data\n\n    def create_target3(self, directory_path):\n\n        cv, oof_preds = self._prepare_cv()\n\n        for fold, (train_index, valid_index) in enumerate(cv.split(self.data)):\n\n            train_data = self.data.iloc[train_index]\n            valid_data = self.data.iloc[valid_index]\n\n                        # 学習時\n# --------------------------------------------------------------------------------------\n            # Nelson-Aalen累積ハザード推定量を計算するためのクラスのインスタンスを作成\n            naf = NelsonAalenFitter()\n\n            naf.fit(durations=train_data['efs_time'], event_observed=train_data['efs'])\n\n\n            # モデルを保存\n            joblib.dump(naf, directory_path / f\"naf_model_fold{fold}.joblib\")\n# -----------------------------------------------------------------------------------------\n# モデルを読み込むとき\n# -----------------------------------------------------------\n            # モデルをロード\n            # naf = joblib.load(directory_path / f\"naf_model_fold{fold}.joblib\")\n# --------------------------------------------------------------------------------\n\n            oof_preds[valid_index] = -naf.cumulative_hazard_at_times(valid_data['efs_time']).values\n\n        self.data['target3'] = oof_preds\n        self.validate_model(oof_preds, 'Nelson-Aalen')\n\n        return self.data\n\n    def create_target4(self):\n\n        self.data['target4'] = self.data.efs_time.copy()\n        self.data.loc[self.data.efs == 0, 'target4'] *= -1\n\n        return self.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.356300Z","iopub.execute_input":"2025-02-23T12:36:51.356663Z","iopub.status.idle":"2025-02-23T12:36:51.382562Z","shell.execute_reply.started":"2025-02-23T12:36:51.356631Z","shell.execute_reply":"2025-02-23T12:36:51.380869Z"},"id":"APSNd_UVngBi"},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from scipy.stats import boxcox\n\nclass MD:\n\n    def __init__(self, color, data, cat_cols, early_stop, penalizer, n_splits):\n\n        self.eda = EDA(color, data)\n        self.targets = Targets(data, cat_cols, penalizer, n_splits)\n\n        self.data = data\n        self.cat_cols = cat_cols\n        self._early_stop = early_stop\n        self.efs_lgb_models = []\n        self.efs_ctb_models = []\n        self.efs_xgb_models = []\n\n    def create_targets(self, lgb_params_efs, ctb_params_efs, xgb_params_efs, directory_path):\n        print(\"target_1開始\")\n        self.data = self.targets.create_target1(directory_path)\n        print(\"target_1完了\")\n        self.data = self.targets.create_target2(directory_path)\n        print(\"target_2完了\")\n        self.data = self.targets.create_target3(directory_path)\n        print(\"target_3完了\")\n        self.data = self.targets.create_target4()\n        print(\"target_4完了\")\n\n\n\n\n        return self.data\n\n    def train_model(self, params, target, title, directory_path):\n\n        cv, oof_preds = self.targets._prepare_cv()\n\n\n        X = self.data.drop(['ID', 'efs', 'efs_time', 'target1', 'target2', 'target3', 'target4'], axis=1)\n        y = self.data[target]\n        w =  1 + self.data[\"efs\"]  # 最小1、最大2の重み\n\n        models, fold_scores = [], []\n\n\n        for fold, (train_index, valid_index) in enumerate(cv.split(X, y)):\n            # 訓練データとバリデーションデータの分割\n            X_train = X.iloc[train_index]\n            X_valid = X.iloc[valid_index]\n            y_train = y.iloc[train_index]\n            y_valid = y.iloc[valid_index]\n            w_train = w.iloc[train_index]\n            w_valid = w.iloc[valid_index]\n\n            # target_encodingをやる場合\n            # # 訓練データとバリデーションデータの分割\n            # X_train = X.iloc[train_index].copy()\n            # X_valid = X.iloc[valid_index].copy()\n            # y_train = y.iloc[train_index]\n            # y_valid = y.iloc[valid_index]\n\n            # `target` を一時的に追加してエンコーディング計算用に利用\n            # X_train['target'] = y_train\n\n            # # カテゴリ変数のターゲットエンコーディング\n            # for col in self.cat_cols:\n            #     # 訓練データで目的変数の平均を計算\n            #     mapping = X_train.groupby(col)['target'].mean()\n\n            #     # バリデーションデータにエンコーディング値を割り当て\n            #     X_valid[col] = X_valid[col].map(mapping).astype(float) # 明示的に float に変換\n\n            #     # 訓練データにもエンコーディング値を割り当て\n            #     X_train[col] = X_train[col].map(mapping).astype(float) # 明示的に float に変換\n\n            # # エンコーディング計算後、`target` を削除\n            # X_train = X_train.drop(columns=['target'])\n\n            if title.startswith('LightGBM'):\n\n                model = lgb.LGBMRegressor(**params)\n\n                model.fit(\n                    X_train,\n                    y_train,\n                    sample_weight=w_train,\n                    eval_set=[(X_valid, y_valid)],\n                    eval_metric='rmse',\n                    callbacks=[lgb.early_stopping(self._early_stop, verbose=1), lgb.log_evaluation(period=1000)]\n                )\n\n                # モデルを保存\n                joblib.dump(model, directory_path / f'lightgbm_model_{target}_fold{fold}.pkl')\n\n            elif title.startswith('CatBoost'):\n\n                model = CatBoostRegressor(**params, verbose=0, cat_features=self.cat_cols)\n\n                # target_encodingの場合\n                # model = CatBoostRegressor(**params, verbose=0, cat_features=[])\n\n                model.fit(\n                    X_train,\n                    y_train,\n                    sample_weight=w_train,\n                    eval_set=(X_valid, y_valid),\n                    early_stopping_rounds=self._early_stop,\n                    verbose=1000\n                )\n                model_file_path = directory_path / f'catboost_model_{target}_fold{fold}.cbm'\n                if target == 'target4':\n                    if params['grow_policy'] == 'Depthwise':\n                        model_file_path = directory_path / f'catboost_model_{target}_Cox1_fold{fold}.cbm'\n                    else:\n                        model_file_path = directory_path / f'catboost_model_{target}_Cox2_fold{fold}.cbm'\n                # モデルを保存\n                model.save_model(model_file_path)\n\n            elif title.startswith('XGBoost'):\n                # データセットの準備\n                X_train = xgb.DMatrix(X_train, label=y_train, weight=w_train, enable_categorical=True)\n                X_valid = xgb.DMatrix(X_valid, label=y_valid, enable_categorical=True)\n\n\n\n                # モデルの学習\n                model = xgb.train(\n                    params=params,\n                    dtrain=X_train,\n                    num_boost_round=10000,                      # 最大イテレーション数\n                    evals=[(X_train, 'train'), (X_valid, 'valid')],  # 学習データと検証データのセット\n                    early_stopping_rounds=self._early_stop,    # CatBoostのearly_stopping_roundsに相当\n                    verbose_eval=1000                          # 学習ログの間隔\n                )\n\n                # モデルの保存\n                model_file_path = directory_path / f'xgboost_model_{target}_fold{fold}.model'\n\n                # JSON形式で保存\n                model.save_model(model_file_path.with_suffix(\".json\"))\n\n                # モデルの読み込み\n                # model = xgb.Booster()\n                # model.load_model(\"xgboost_model_target1_fold0.json\")\n\n\n\n            models.append(model)\n\n            oof_preds[valid_index] = model.predict(X_valid)\n\n            y_true_fold = self.data.iloc[valid_index][['ID', 'efs', 'efs_time', 'race_group']].copy()\n            y_pred_fold = self.data.iloc[valid_index][['ID']].copy()\n\n            y_pred_fold['prediction'] = oof_preds[valid_index]\n\n            fold_score = score(y_true_fold, y_pred_fold, 'ID')\n            fold_scores.append(fold_score)\n\n        self.eda._plot_cv(fold_scores, title)\n        self.targets.validate_model(oof_preds, title)\n\n        return models, oof_preds\n\n    def infer_model(self, data, models, target):\n\n        data = data.drop(['ID'], axis=1)\n\n        for col in self.cat_cols:\n            data[col] = data[col].astype('category')\n\n        efs_pred_lgb = np.mean([model.predict(data) for model in self.efs_lgb_models], axis=0)\n        efs_pred_ctb = np.mean([model.predict(data) for model in self.efs_ctb_models], axis=0)\n        efs_pred_xgb = np.mean([model.predict(xgb.DMatrix(data, enable_categorical=True)) for model in self.efs_xgb_models], axis=0)\n\n        data[\"efs_pred_lgb\"] = efs_pred_lgb\n        data[\"efs_pred_ctb\"] = efs_pred_ctb\n        data[\"efs_pred_xgb\"] = efs_pred_xgb\n\n        # # カテゴリ変数のターゲットエンコーディング\n        # for col in self.cat_cols:\n        #     # 訓練データで目的変数の平均を計算\n        #     mapping = self.data.groupby(col)[target].mean()\n\n        #     # バリデーションデータにエンコーディング値を割り当て\n        #     data[col] = data[col].map(mapping).astype(float) # 明示的に float に変換\n\n        return np.mean([model.predict(data) for model in models], axis=0)\n\n    def infer_model_xgb(self, data, models, target):\n        \n        for col in self.cat_cols:\n            data[col] = data[col].astype('category')\n            \n        data = data.drop(['ID'], axis=1)\n        efs_pred_lgb = np.mean([model.predict(data) for model in self.efs_lgb_models], axis=0)\n        efs_pred_ctb = np.mean([model.predict(data) for model in self.efs_ctb_models], axis=0)\n        efs_pred_xgb = np.mean([model.predict(xgb.DMatrix(data, enable_categorical=True)) for model in self.efs_xgb_models], axis=0)\n\n        data[\"efs_pred_lgb\"] = efs_pred_lgb\n        data[\"efs_pred_ctb\"] = efs_pred_ctb\n        data[\"efs_pred_xgb\"] = efs_pred_xgb\n        # for col in self.cat_cols:\n        #     for fold, encoders in self.fold_encoders[target].items():\n        #         lbl = encoders[col]\n        #         data[col] = data[col].map(lambda x: lbl.transform([x])[0] if x in lbl.classes_ else -1)\n        # テストデータをDMatrixに変換\n        dtest = xgb.DMatrix(data, enable_categorical=True)\n\n        return np.mean([model.predict(dtest) for model in models], axis=0)","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.039648,"end_time":"2024-12-13T13:23:12.295144","exception":false,"start_time":"2024-12-13T13:23:12.255496","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.383617Z","iopub.execute_input":"2025-02-23T12:36:51.383994Z","iopub.status.idle":"2025-02-23T12:36:51.410997Z","shell.execute_reply.started":"2025-02-23T12:36:51.383946Z","shell.execute_reply":"2025-02-23T12:36:51.409582Z"},"id":"E9zbdzZqngBm"},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def reduce_memory_usage(df):\n    \"\"\"データフレームのメモリ使用量を削減する関数\"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(f'メモリ使用量: {start_mem:.2f} MB')\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:  # 数値型のみ処理\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                # if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #     df[col] = df[col].astype(np.float16)\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(f'メモリ削減後: {end_mem:.2f} MB ({100 - 100 * end_mem / start_mem:.1f}% 減少)')\n    return df\n\ntrain_data = reduce_memory_usage(train_data)\ntest_data = reduce_memory_usage(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.412626Z","iopub.execute_input":"2025-02-23T12:36:51.413121Z","iopub.status.idle":"2025-02-23T12:36:51.482740Z","shell.execute_reply.started":"2025-02-23T12:36:51.413044Z","shell.execute_reply":"2025-02-23T12:36:51.481609Z"},"id":"-xFH03EnngBm","outputId":"5bd2b702-cea1-449e-b431-b0d67abf76bd"},"outputs":[{"name":"stdout","text":"メモリ使用量: 11.76 MB\nメモリ削減後: 11.26 MB (4.2% 減少)\nメモリ使用量: 0.00 MB\nメモリ削減後: 0.00 MB (3.9% 減少)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"md = MD(CFG.color, train_data, cat_cols, CFG.early_stop, CFG.penalizer, CFG.n_splits)","metadata":{"_kg_hide-input":false,"papermill":{"duration":0.01829,"end_time":"2024-12-13T13:23:12.32397","exception":false,"start_time":"2024-12-13T13:23:12.30568","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.483965Z","iopub.execute_input":"2025-02-23T12:36:51.484380Z","iopub.status.idle":"2025-02-23T12:36:51.489993Z","shell.execute_reply.started":"2025-02-23T12:36:51.484348Z","shell.execute_reply":"2025-02-23T12:36:51.488213Z"},"id":"YaiIGyrgngBm"},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# 現在の日時を取得してフォーマット\ncurrent_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n# ディレクトリ名を作成\ndirectory_name = f\"model_{current_datetime}\"\n\n# ディレクトリのパスを指定\ndirectory_path = Path(directory_name)\n\n# ディレクトリを作成\ndirectory_path.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.491528Z","iopub.execute_input":"2025-02-23T12:36:51.491954Z","iopub.status.idle":"2025-02-23T12:36:51.510441Z","shell.execute_reply.started":"2025-02-23T12:36:51.491921Z","shell.execute_reply":"2025-02-23T12:36:51.508935Z"},"id":"aNOlDVVPngBn"},"outputs":[],"execution_count":37},{"cell_type":"code","source":"train_data = md.create_targets(CFG.lgb_params_efs, CFG.ctb_params_efs, CFG.xgb_params_efs, directory_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T12:36:51.511818Z","iopub.execute_input":"2025-02-23T12:36:51.512209Z"},"id":"gNlUt-9PngBn","outputId":"42ea5769-ad31-45d9-97e6-f05f3c1aecc1"},"outputs":[{"name":"stdout","text":"target_1開始\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# md.data[\"target1\"], _ = yeojohnson(md.data['target1'])\n# md.data[\"target2\"], _ = yeojohnson(md.data['target2'])\n# md.data[\"target3\"], _ = yeojohnson(md.data['target3'])\n# md.data[\"target4\"], _ = yeojohnson(md.data['target4'])\n\n# train_data = md.data\n\n\n# display(train_data.head)","metadata":{"trusted":true,"id":"SXg_is-6ngBn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"md.eda.distribution_plot('target1', 'Cox Target')","metadata":{"papermill":{"duration":39.008232,"end_time":"2024-12-13T13:23:51.341762","exception":false,"start_time":"2024-12-13T13:23:12.33353","status":"completed"},"tags":[],"trusted":true,"id":"5xJ3pSUtngBn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"md.eda.distribution_plot('target2', 'Kaplan-Meier Target')","metadata":{"papermill":{"duration":0.180799,"end_time":"2024-12-13T13:23:51.538524","exception":false,"start_time":"2024-12-13T13:23:51.357725","status":"completed"},"tags":[],"trusted":true,"id":"ZM4hPrrHngBn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"md.eda.distribution_plot('target3', 'Nelson-Aalen Target')","metadata":{"papermill":{"duration":0.169091,"end_time":"2024-12-13T13:23:51.718819","exception":false,"start_time":"2024-12-13T13:23:51.549728","status":"completed"},"tags":[],"trusted":true,"id":"QU57j0QFngBn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"md.eda.distribution_plot('target4', 'Target for Cox-Loss Models')","metadata":{"trusted":true,"id":"3rhT9PS9ngBn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fe.info(train_data)","metadata":{"papermill":{"duration":0.079694,"end_time":"2024-12-13T13:23:51.808887","exception":false,"start_time":"2024-12-13T13:23:51.729193","status":"completed"},"tags":[],"trusted":true,"id":"UrsBA4oxngBn"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Models with Cox Target</p>","metadata":{"papermill":{"duration":0.011062,"end_time":"2024-12-13T13:23:51.83194","exception":false,"start_time":"2024-12-13T13:23:51.820878","status":"completed"},"tags":[],"id":"qEKz_R3ongBn"}},{"cell_type":"code","source":"xgb1_models, xgb1_oof_preds = md.train_model(CFG.xgb_params, target='target1', title='XGBoost', directory_path=directory_path)","metadata":{"trusted":true,"id":"YHM03pYqngBn","execution":{"iopub.status.busy":"2025-02-23T12:33:16.023442Z","iopub.status.idle":"2025-02-23T12:33:16.023765Z","shell.execute_reply":"2025-02-23T12:33:16.023637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb1_models, lgb1_oof_preds = md.train_model(CFG.lgb_params_1, target='target1', title='LightGBM', directory_path=directory_path)","metadata":{"trusted":true,"id":"mKDusu0RngBn","execution":{"iopub.status.busy":"2025-02-23T12:33:16.025132Z","iopub.status.idle":"2025-02-23T12:33:16.025547Z","shell.execute_reply":"2025-02-23T12:33:16.025347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ctb1_models, ctb1_oof_preds = md.train_model(CFG.ctb_params_1, target='target1', title='CatBoost', directory_path=directory_path)\n# 現在のイテレーション数（エポック数）, トレーニングデータに対する損失関数の値, 検証データに対する損失関数の, 検証データでのこれまでの最良の損失関数の値と、それが達成されたイテレーション番号, トレーニングの開始から現在のイテレーションまでに経過した合計時間, 現在の速度でトレーニングが継続した場合に予想される残り時間","metadata":{"papermill":{"duration":4808.205155,"end_time":"2024-12-13T14:44:00.048534","exception":false,"start_time":"2024-12-13T13:23:51.843379","status":"completed"},"tags":[],"trusted":true,"id":"6cgbfXqMngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.026644Z","iopub.status.idle":"2025-02-23T12:33:16.027074Z","shell.execute_reply":"2025-02-23T12:33:16.026850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb1_preds = md.infer_model_xgb(test_data, xgb1_models, 'target1')","metadata":{"trusted":true,"id":"D-9UOkQOngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.027734Z","iopub.status.idle":"2025-02-23T12:33:16.028161Z","shell.execute_reply":"2025-02-23T12:33:16.027961Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb1_preds = md.infer_model(test_data, lgb1_models, 'target1')","metadata":{"trusted":true,"id":"EWAbArYengBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.029137Z","iopub.status.idle":"2025-02-23T12:33:16.029619Z","shell.execute_reply":"2025-02-23T12:33:16.029415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ctb1_preds = md.infer_model(test_data, ctb1_models, 'target1')","metadata":{"papermill":{"duration":0.071675,"end_time":"2024-12-13T14:48:51.427728","exception":false,"start_time":"2024-12-13T14:48:51.356053","status":"completed"},"tags":[],"trusted":true,"id":"DITh3_-fngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.030494Z","iopub.status.idle":"2025-02-23T12:33:16.030940Z","shell.execute_reply":"2025-02-23T12:33:16.030748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Models with Kaplan-Meier Target</p>","metadata":{"papermill":{"duration":0.010491,"end_time":"2024-12-13T14:48:51.662203","exception":false,"start_time":"2024-12-13T14:48:51.651712","status":"completed"},"tags":[],"id":"9LhvSPoCngBo"}},{"cell_type":"code","source":"xgb2_models, xgb2_oof_preds = md.train_model(CFG.xgb_params, target='target2', title='XGBoost', directory_path=directory_path)","metadata":{"trusted":true,"id":"2K3MB3MxngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.032177Z","iopub.status.idle":"2025-02-23T12:33:16.032642Z","shell.execute_reply":"2025-02-23T12:33:16.032431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ctb2_models, ctb2_oof_preds = md.train_model(CFG.ctb_params_23, target='target2', title='CatBoost', directory_path=directory_path)","metadata":{"papermill":{"duration":2470.336385,"end_time":"2024-12-13T15:30:02.009405","exception":false,"start_time":"2024-12-13T14:48:51.67302","status":"completed"},"tags":[],"trusted":true,"id":"VevZ-q1cngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.033550Z","iopub.status.idle":"2025-02-23T12:33:16.033999Z","shell.execute_reply":"2025-02-23T12:33:16.033806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb2_models, lgb2_oof_preds = md.train_model(CFG.lgb_params_23, target='target2', title='LightGBM', directory_path=directory_path)","metadata":{"papermill":{"duration":38.457069,"end_time":"2024-12-13T15:30:40.477711","exception":false,"start_time":"2024-12-13T15:30:02.020642","status":"completed"},"tags":[],"trusted":true,"id":"Apz2IevyngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.034986Z","iopub.status.idle":"2025-02-23T12:33:16.035403Z","shell.execute_reply":"2025-02-23T12:33:16.035233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb2_preds = md.infer_model_xgb(test_data, xgb2_models, 'target2')","metadata":{"trusted":true,"id":"Xnd-zn2DngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.040424Z","iopub.execute_input":"2025-02-23T12:33:16.040955Z","iopub.status.idle":"2025-02-23T12:33:16.059972Z","shell.execute_reply.started":"2025-02-23T12:33:16.040913Z","shell.execute_reply":"2025-02-23T12:33:16.054637Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d8c1583f3930>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb2_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_model_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb2_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'md' is not defined"],"ename":"NameError","evalue":"name 'md' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"ctb2_preds = md.infer_model(test_data, ctb2_models, 'target2')","metadata":{"papermill":{"duration":0.073959,"end_time":"2024-12-13T15:30:40.563068","exception":false,"start_time":"2024-12-13T15:30:40.489109","status":"completed"},"tags":[],"trusted":true,"id":"C6DAAIBlngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.061166Z","iopub.status.idle":"2025-02-23T12:33:16.061708Z","shell.execute_reply":"2025-02-23T12:33:16.061471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb2_preds = md.infer_model(test_data, lgb2_models, 'target2')","metadata":{"papermill":{"duration":0.170712,"end_time":"2024-12-13T15:30:40.747856","exception":false,"start_time":"2024-12-13T15:30:40.577144","status":"completed"},"tags":[],"trusted":true,"id":"upYKkDuXngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.062763Z","iopub.status.idle":"2025-02-23T12:33:16.063286Z","shell.execute_reply":"2025-02-23T12:33:16.063041Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Models with Nelson-Aalen Target</p>","metadata":{"papermill":{"duration":0.011016,"end_time":"2024-12-13T15:30:40.770359","exception":false,"start_time":"2024-12-13T15:30:40.759343","status":"completed"},"tags":[],"id":"IBA-K8kPngBo"}},{"cell_type":"code","source":"xgb3_models, xgb3_oof_preds = md.train_model(CFG.xgb_params, target='target3', title='XGBoost', directory_path=directory_path)","metadata":{"trusted":true,"id":"simFaCj2ngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.064531Z","iopub.status.idle":"2025-02-23T12:33:16.064917Z","shell.execute_reply":"2025-02-23T12:33:16.064772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ctb3_models, ctb3_oof_preds = md.train_model(CFG.ctb_params_23, target='target3', title='CatBoost', directory_path=directory_path)","metadata":{"papermill":{"duration":2199.149038,"end_time":"2024-12-13T16:07:19.930791","exception":false,"start_time":"2024-12-13T15:30:40.781753","status":"completed"},"tags":[],"trusted":true,"id":"OZ5XZ4hOngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.066178Z","iopub.status.idle":"2025-02-23T12:33:16.066673Z","shell.execute_reply":"2025-02-23T12:33:16.066465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb3_models, lgb3_oof_preds = md.train_model(CFG.lgb_params_23, target='target3', title='LightGBM', directory_path=directory_path)","metadata":{"papermill":{"duration":35.221097,"end_time":"2024-12-13T16:07:55.163635","exception":false,"start_time":"2024-12-13T16:07:19.942538","status":"completed"},"tags":[],"trusted":true,"id":"Yec8JYUqngBo","execution":{"iopub.status.busy":"2025-02-23T12:33:16.067564Z","iopub.status.idle":"2025-02-23T12:33:16.068003Z","shell.execute_reply":"2025-02-23T12:33:16.067825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb3_preds = md.infer_model_xgb(test_data, xgb2_models, 'target3')","metadata":{"trusted":true,"id":"2TgFAz9xngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.069094Z","iopub.status.idle":"2025-02-23T12:33:16.069534Z","shell.execute_reply":"2025-02-23T12:33:16.069347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ctb3_preds = md.infer_model(test_data, ctb3_models, 'target3')","metadata":{"papermill":{"duration":0.06646,"end_time":"2024-12-13T16:07:55.241797","exception":false,"start_time":"2024-12-13T16:07:55.175337","status":"completed"},"tags":[],"trusted":true,"id":"Lx4-GYpAngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.071309Z","iopub.status.idle":"2025-02-23T12:33:16.071793Z","shell.execute_reply":"2025-02-23T12:33:16.071585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb3_preds = md.infer_model(test_data, lgb3_models, 'target3')","metadata":{"papermill":{"duration":0.164669,"end_time":"2024-12-13T16:07:55.41872","exception":false,"start_time":"2024-12-13T16:07:55.254051","status":"completed"},"tags":[],"trusted":true,"id":"KzF9w7SYngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.072475Z","iopub.status.idle":"2025-02-23T12:33:16.072896Z","shell.execute_reply":"2025-02-23T12:33:16.072711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Cox-Loss Models</p>","metadata":{"id":"12XTPWCYngBp"}},{"cell_type":"code","source":"cox1_models, cox1_oof_preds = md.train_model(CFG.cox1_params, target='target4', title='CatBoost', directory_path=directory_path)","metadata":{"trusted":true,"id":"294xIZTMngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.073712Z","iopub.status.idle":"2025-02-23T12:33:16.074192Z","shell.execute_reply":"2025-02-23T12:33:16.073973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cox2_models, cox2_oof_preds = md.train_model(CFG.cox2_params, target='target4', title='CatBoost', directory_path=directory_path)","metadata":{"trusted":true,"id":"uZ4uHfBSngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.075256Z","iopub.status.idle":"2025-02-23T12:33:16.075671Z","shell.execute_reply":"2025-02-23T12:33:16.075488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n#  # データフレームに変換\n# importance_df = pd.DataFrame(columns = ['Feature', 'Importance'])\n\n# for module_models in models:\n#     for model in module_models:\n\n#         # 特徴量の重要度を取得\n#         importance = model.feature_importances_\n#         features = train_data.drop(['ID', 'efs', 'efs_time', 'target1', 'target2', 'target3', 'target4'], axis=1).columns  # 特徴量の名前を取得\n\n#         # データフレームに変換\n#         importance_df_temp = pd.DataFrame({'Feature': features, 'Importance': importance})\n\n#         # 重要度の合計を計算\n#         total_importance = importance_df_temp['Importance'].sum()\n\n#         # 正規化を行う\n#         importance_df_temp['Normalized_Importance'] = importance_df_temp['Importance'] / total_importance\n\n\n\n# # 重要度でソート\n# importance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# # 数値で表示\n# print(importance_df)\n# # 特徴量の重要度を可視化\n\n#         # plt.figure(figsize=(10, 10))\n#         # plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n#         # plt.xlabel('Importance')\n#         # plt.title('Feature Importance')\n#         # plt.gca().invert_yaxis()  # 特徴量名が上から表示されるように反転\n#         # plt.show()","metadata":{"trusted":true,"id":"ozkLg3etngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.076627Z","iopub.status.idle":"2025-02-23T12:33:16.077050Z","shell.execute_reply":"2025-02-23T12:33:16.076862Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 特徴量の重要度","metadata":{"id":"W6ObiSNungBp"}},{"cell_type":"code","source":"# models = [\n#     ctb1_models,\n#     lgb1_models,\n#     ctb2_models,\n#     lgb2_models,\n#     ctb3_models,\n#     lgb3_models,\n#     cox1_models,\n#     cox2_models\n# ]\n\n# models_name = [\n#     \"ctb1_models\",\n#     \"lgb1_models\",\n#     \"ctb2_models\",\n#     \"lgb2_models\",\n#     \"ctb3_models\",\n#     \"lgb3_models\",\n#     \"cox1_models\",\n#     \"cox2_models\"\n# ]\n\n\n\n# for module_models, model_name in zip(models, models_name):\n#     # 特徴量とその重要度を保存するリストを初期化\n#     importance_list = []\n#     for model in module_models:\n\n#         # 特徴量の重要度を取得\n#         importance = model.feature_importances_\n#         features = train_data.drop(['ID', 'efs', 'efs_time', 'target1', 'target2', 'target3', 'target4'], axis=1).columns  # 特徴量の名前を取得\n\n#         # データフレームに変換\n#         importance_df_temp = pd.DataFrame({'Feature': features, 'Importance': importance})\n\n#         # 重要度の合計を計算\n#         total_importance = importance_df_temp['Importance'].sum()\n\n#         # 正規化を行う\n#         importance_df_temp['Normalized_Importance'] = importance_df_temp['Importance'] / total_importance\n\n#         # 正規化された重要度をリストに追加\n#         for idx, row in importance_df_temp.iterrows():\n#             feature = row['Feature']\n#             normalized_importance = row['Normalized_Importance']\n#             importance_list.append({'Feature': feature, 'Normalized_Importance': normalized_importance})\n\n#     # DataFrameを作成\n#     importance_df = pd.DataFrame(importance_list)\n\n#     # 各特徴量の正規化された重要度を合計\n#     final_importance_df = importance_df.groupby('Feature', as_index=False).sum()\n\n#     # 重要度でソート\n#     final_importance_df = final_importance_df.sort_values(by='Normalized_Importance', ascending=False)\n\n#     # 最終的な正規化された重要度を表示\n#     print(model_name)\n#     print(final_importance_df)","metadata":{"trusted":true,"id":"tOteBc_9ngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.078732Z","iopub.status.idle":"2025-02-23T12:33:16.079226Z","shell.execute_reply":"2025-02-23T12:33:16.078998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n\n# models = [\n#     ctb1_models,\n#     lgb1_models,\n#     ctb2_models,\n#     lgb2_models,\n#     ctb3_models,\n#     lgb3_models,\n#     cox1_models,\n#     cox2_models\n# ]\n\n# models_name = [\n#     \"ctb1_models\",\n#     \"lgb1_models\",\n#     \"ctb2_models\",\n#     \"lgb2_models\",\n#     \"ctb3_models\",\n#     \"lgb3_models\",\n#     \"cox1_models\",\n#     \"cox2_models\"\n# ]\n\n# # 不要な列をドロップしたあとの \"学習に使う特徴量\" を取得\n# features = train_data.drop(\n#     ['ID', 'efs', 'efs_time', 'target1', 'target2', 'target3', 'target4'],\n#     axis=1\n# ).columns\n\n# for module_models, model_name in zip(models, models_name):\n#     # foldごとの特徴量重要度データフレームをまとめるリスト\n#     fold_importance_dfs = []\n\n#     # クロスバリデーションの各モデルを順番に取り出す\n#     for model in module_models:\n#         # この fold の生の重要度を取得\n#         importance = model.feature_importances_\n\n#         # DataFrameに変換\n#         importance_df_temp = pd.DataFrame({\n#             'Feature': features,\n#             'Importance': importance\n#         })\n\n#         # この fold 内での合計重要度\n#         total_importance = importance_df_temp['Importance'].sum()\n\n#         # fold 内で正規化（sum=1 となるようにする）\n#         # 万が一、total_importance が 0 の場合はエラー回避\n#         if total_importance == 0:\n#             importance_df_temp['Normalized_Importance'] = 0\n#         else:\n#             importance_df_temp['Normalized_Importance'] = (\n#                 importance_df_temp['Importance'] / total_importance\n#             )\n\n#         # この fold の結果をリストに追加\n#         fold_importance_dfs.append(importance_df_temp[['Feature', 'Normalized_Importance']])\n\n#     # 全 fold の重要度データフレームを結合\n#     all_folds_importance = pd.concat(fold_importance_dfs, axis=0)\n\n#     # 特徴量ごとに「平均の正規化重要度」を計算\n#     # sum ではなく mean をとる方が、fold 数によらず比較しやすい\n#     final_importance_df = (\n#         all_folds_importance\n#         .groupby('Feature', as_index=False)['Normalized_Importance']\n#         .mean()\n#         .sort_values(by='Normalized_Importance', ascending=False)\n#     )\n\n#     # 結果を表示\n#     print(f\"Feature Importance for {model_name}\")\n#     print(final_importance_df)\n#     print(\"-\" * 50)\n","metadata":{"trusted":true,"id":"C1MiZ6ObngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.080096Z","iopub.status.idle":"2025-02-23T12:33:16.080539Z","shell.execute_reply":"2025-02-23T12:33:16.080347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # データフレームに変換\nimportance_df = pd.DataFrame(columns = ['Feature', 'Importance'])\nimportance_df","metadata":{"trusted":true,"id":"xP81f-BhngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.081533Z","iopub.status.idle":"2025-02-23T12:33:16.082007Z","shell.execute_reply":"2025-02-23T12:33:16.081796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cox1_preds = md.infer_model(test_data, cox1_models, 'target4')","metadata":{"trusted":true,"id":"d0y1mpHongBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.083206Z","iopub.status.idle":"2025-02-23T12:33:16.083678Z","shell.execute_reply":"2025-02-23T12:33:16.083459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cox2_preds = md.infer_model(test_data, cox2_models, 'target4')","metadata":{"trusted":true,"id":"z--iVVoVngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.084463Z","iopub.status.idle":"2025-02-23T12:33:16.084915Z","shell.execute_reply":"2025-02-23T12:33:16.084722Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"background-color: rgb(247, 230, 202); font-size: 300%; text-align: center; border-radius: 40px 40px; color: rgb(162, 87, 79); font-weight: bold; font-family: 'Roboto'; border: 4px solid rgb(162, 87, 79);\">Ensemble Model</p>","metadata":{"papermill":{"duration":0.01174,"end_time":"2024-12-13T16:07:55.442686","exception":false,"start_time":"2024-12-13T16:07:55.430946","status":"completed"},"tags":[],"id":"1I1viFONngBp"}},{"cell_type":"markdown","source":"<div style=\"background-color: rgb(247, 230, 202); border: 4px solid rgb(162, 87, 79); border-radius: 40px; padding: 20px; font-family: 'Roboto'; color: rgb(162, 87, 79); text-align: left; font-size: 140%;\">\n    <b>Calculate C-Index score for Ensemble model using Out-of-Fold (OOF) predictions.</b>\n</div>","metadata":{"id":"JN0jW531ngBp"}},{"cell_type":"code","source":"oof_preds = [\n    ctb1_oof_preds,\n    lgb1_oof_preds,\n    xgb1_oof_preds,\n    ctb2_oof_preds,\n    lgb2_oof_preds,\n    xgb2_oof_preds,\n    ctb3_oof_preds,\n    lgb3_oof_preds,\n    xgb3_oof_preds,\n    cox1_oof_preds,\n    cox2_oof_preds\n]","metadata":{"trusted":true,"id":"u-7jApsQngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.085875Z","iopub.status.idle":"2025-02-23T12:33:16.086347Z","shell.execute_reply":"2025-02-23T12:33:16.086153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ranked_oof_preds = np.array([rankdata(p) for p in oof_preds])","metadata":{"trusted":true,"id":"bqVvZuYmngBp","execution":{"iopub.status.busy":"2025-02-23T12:33:16.087280Z","iopub.status.idle":"2025-02-23T12:33:16.087734Z","shell.execute_reply":"2025-02-23T12:33:16.087528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ensemble_oof_preds = np.dot(CFG.weights, ranked_oof_preds)","metadata":{"trusted":true,"id":"k06BBJXUngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.088429Z","iopub.status.idle":"2025-02-23T12:33:16.088871Z","shell.execute_reply":"2025-02-23T12:33:16.088679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# md.targets.validate_model(ensemble_oof_preds, 'Ensemble Model')","metadata":{"trusted":true,"id":"_T_gQrj9ngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.089749Z","iopub.status.idle":"2025-02-23T12:33:16.091310Z","shell.execute_reply":"2025-02-23T12:33:16.091099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# best_score = 0\n# best_i = 0\n# best_k = 0\n# for i in range(51):\n#     for k in range(51-i):\n#         for j in range(51-i-k):\n#             if k >= 0 and i >= 0 and j >= 0 and 51-i-k-j >= 0:\n#                 CFG.weights = [i, i, k, k, j, j, 101-i-k-j, 101-i-k-j]\n#                 ensemble_oof_preds = np.dot(CFG.weights, ranked_oof_preds)\n#                 curent_score = md.targets.validate_model(ensemble_oof_preds, 'Ensemble Model')\n#                 if best_score < curent_score:\n#                     best_i = i\n#                     best_k = k\n#                     best_j = j\n#                     best_score = curent_score\n\n# print(f\"best_score->{best_score}, best_i->{best_i}, best_k->{best_k}, best_j->{best_j}\")\n# CFG.weights = [best_i, best_i, best_k, best_k, best_j, best_j, 101-best_i-best_k-best_j, 101-best_i-best_k-best_j]","metadata":{"trusted":true,"id":"0fyhxHlbngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.092076Z","iopub.status.idle":"2025-02-23T12:33:16.092512Z","shell.execute_reply":"2025-02-23T12:33:16.092319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\n# 目的関数の定義\ndef objective(trial):\n    # 各モデルの重みを提案 (0.0～1.0 の範囲)\n    weights = [trial.suggest_float(f'weight_{i}', 0.05, 1.0) for i in range(len(ranked_oof_preds))]\n\n    # 重みの正規化（合計が1になるようにスケーリング）\n    weights = np.array(weights)\n    weights /= np.sum(weights)\n\n    # アンサンブル予測を計算 (加重平均)\n    ensemble_oof_preds = np.dot(weights, ranked_oof_preds)\n\n    curent_score = md.targets.validate_model(ensemble_oof_preds, 'Ensemble Model')\n\n    return curent_score  # 最大化が目標\n\n# Optunaによる最適化\nstudy = optuna.create_study(direction='maximize')  # AUCを最大化\nstudy.optimize(objective, n_trials=200)\n\n# 最適な重み\nprint(\"Best Weights:\", study.best_params)\nprint(\"Best AUC:\", study.best_value)\n\nCFG.weights = [1 for _ in range(len(ranked_oof_preds))]\nnp.array(CFG.weights)\n\nfor i in range(len(CFG.weights)):\n    CFG.weights[i] = study.best_params[f'weight_{i}']","metadata":{"trusted":true,"id":"JrDxPr0zngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.093380Z","iopub.status.idle":"2025-02-23T12:33:16.093813Z","shell.execute_reply":"2025-02-23T12:33:16.093624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# oof_preds_name = [\n#     \"ctb1_oof_preds\",\n#     \"lgb1_oof_preds\",\n#     \"ctb2_oof_preds\",\n#     \"lgb2_oof_preds\",\n#     \"ctb3_oof_preds\",\n#     \"lgb3_oof_preds\",\n#     \"cox1_oof_preds\",\n#     \"cox2_oof_preds\"\n# ]\n\n# for i, oof_pred in enumerate(oof_preds):\n#     means = []\n#     for pred in oof_pred:\n#         means.append(np.mean(pred))\n\n#     print(f\"{oof_preds_name[i]}->{np.mean(means)}\")\n","metadata":{"trusted":true,"id":"ZZ0CCM3vngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.094689Z","iopub.status.idle":"2025-02-23T12:33:16.095150Z","shell.execute_reply":"2025-02-23T12:33:16.094934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"background-color: rgb(247, 230, 202); border: 4px solid rgb(162, 87, 79); border-radius: 40px; padding: 20px; font-family: 'Roboto'; color: rgb(162, 87, 79); text-align: left; font-size: 140%;\">\n    <b>Ensemble predictions for the test data.</b>\n</div>","metadata":{"id":"zvUj9j1xngBq"}},{"cell_type":"code","source":"preds = [\n    ctb1_preds,\n    lgb1_preds,\n    xgb1_preds,\n    ctb2_preds,\n    lgb2_preds,\n    xgb2_preds,\n    ctb3_preds,\n    lgb3_preds,\n    xgb3_preds,\n    cox1_preds,\n    cox2_preds\n]","metadata":{"papermill":{"duration":0.019704,"end_time":"2024-12-13T16:07:55.474253","exception":false,"start_time":"2024-12-13T16:07:55.454549","status":"completed"},"tags":[],"trusted":true,"id":"DnxQE5l2ngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.096386Z","iopub.status.idle":"2025-02-23T12:33:16.096847Z","shell.execute_reply":"2025-02-23T12:33:16.096646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# rankdataデータセットの要素を順位付けするための関数です。この関数を使用することで、数値データをランキング形式に変換\n# 例えば、リスト [10, 20, 20, 30] に対してランク付けを行うと [1.0, 3.0, 3.0, 4.0] という結果が得られます。\n\nranked_preds = np.array([rankdata(p) for p in preds])","metadata":{"papermill":{"duration":0.023045,"end_time":"2024-12-13T16:07:55.510197","exception":false,"start_time":"2024-12-13T16:07:55.487152","status":"completed"},"tags":[],"trusted":true,"id":"S7ABF4ZcngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.097906Z","iopub.status.idle":"2025-02-23T12:33:16.098393Z","shell.execute_reply":"2025-02-23T12:33:16.098194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_preds = np.dot(CFG.weights, ranked_preds)","metadata":{"papermill":{"duration":0.020168,"end_time":"2024-12-13T16:07:55.542141","exception":false,"start_time":"2024-12-13T16:07:55.521973","status":"completed"},"tags":[],"trusted":true,"id":"mGRi25hcngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.100022Z","iopub.status.idle":"2025-02-23T12:33:16.100486Z","shell.execute_reply":"2025-02-23T12:33:16.100298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"subm_data = pd.read_csv(CFG.subm_path)\nsubm_data['prediction'] = ensemble_preds","metadata":{"papermill":{"duration":0.043145,"end_time":"2024-12-13T16:07:55.596856","exception":false,"start_time":"2024-12-13T16:07:55.553711","status":"completed"},"tags":[],"trusted":true,"id":"rye1PBgdngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.106661Z","iopub.status.idle":"2025-02-23T12:33:16.107183Z","shell.execute_reply":"2025-02-23T12:33:16.106985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"subm_data.to_csv('submission.csv', index=False)\ndisplay(subm_data.head())","metadata":{"papermill":{"duration":0.027273,"end_time":"2024-12-13T16:07:55.636582","exception":false,"start_time":"2024-12-13T16:07:55.609309","status":"completed"},"tags":[],"trusted":true,"id":"pMESW3HEngBq","execution":{"iopub.status.busy":"2025-02-23T12:33:16.108843Z","iopub.status.idle":"2025-02-23T12:33:16.109499Z","shell.execute_reply":"2025-02-23T12:33:16.109229Z"}},"outputs":[],"execution_count":null}]}